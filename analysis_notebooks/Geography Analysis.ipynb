{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geography Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. Fill in the dataset in section 1.1\n",
    "\n",
    "2. Run all cells\n",
    "\n",
    "3. Review the summary pdf generated AND/OR explore each metric below.\n",
    "    - All metrics are identified by a short keyword, and consist of a \"Setup\" and \"Analyses\" portion. The \"Setup\" portion contains code that does not need to be modified unless customization is needed, and the \"Analyses\" portion provides an interactive display of the results.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Initial Setup](#setup) <br/>\n",
    "    1.1 [Dataset](#dataset)\n",
    "2. geo_ctr Metric: [Country Counts](#geo_ctr)<br/>\n",
    "    2.1 [Setup](#geo_ctr_setup)<br/>\n",
    "    2.2 [Analyses](#geo_ctr_analyses)\n",
    "3. geo_tag Metric: [Image Tags](#geo_tag)<br/>\n",
    "    3.1 [Setup](#geo_tag_setup)<br/>\n",
    "    3.2 [Analyses](#geo_tag_analyses)\n",
    "4. geo_lng Metric: [Languages for tourist vs local](#geo_lng) <br/>\n",
    "    4.1 [Setup](#geo_lng_setup)<br/>\n",
    "    4.2 [Analyses](#geo_lng_analyses)\n",
    "5. [Setting up summary pdf](#summarypdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup \n",
    "<a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "try: \n",
    "    import datasets\n",
    "except ModuleNotFoundError: # switch to parent directory on first run \n",
    "    os.chdir(os.pardir)\n",
    "print(os.getcwd())\n",
    "import pickle\n",
    "import itertools\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import PIL.Image\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from math import sqrt\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from scipy.spatial.distance import squareform\n",
    "import pycountry\n",
    "from geonamescache import GeonamesCache\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "try: \n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "except (FileNotFoundError, ModuleNotFoundError) as e: \n",
    "    print(e, '\\n', 'Please refer to \\'Potential Environment Issues\\' on the README page to resolve. ')\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "try: \n",
    "    from countryinfo import CountryInfo\n",
    "except (FileNotFoundError, ModuleNotFoundError) as e: \n",
    "    print(e, '\\n', 'Please refer to \\'Potential Environment Issues\\' on the README page to resolve. ')\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "import re\n",
    "import copy\n",
    "import textwrap\n",
    "import matplotlib.patches as mpatches\n",
    "import operator\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import imageio\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, HBox, Layout\n",
    "import ipywidgets as widgets\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display, HTML, Image\n",
    "import time\n",
    "import warnings\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = sns.color_palette('Set2', 2)\n",
    "SAME_EXTENT = (-0.5, 6.5, -0.5, 6.5)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not os.path.exists(\"dataloader_files\"):\n",
    "    os.mkdir(\"dataloader_files\")\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.mkdir(\"checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/31517194/how-to-hide-one-specific-cell-input-or-output-in-ipython-notebook\n",
    "def hide_toggle(for_next=False, toggle_text='Toggle show/hide'):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True, toggle_text='Show/hide helper functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder(num, folder):\n",
    "    if not os.path.exists(\"results/{0}/{1}\".format(folder, num)):\n",
    "        os.mkdir(\"results/{0}/{1}\".format(folder, num))\n",
    "    file = open(\"results/{0}/{1}/results.txt\".format(folder, num), \"w\")\n",
    "    return file\n",
    "\n",
    "# Projecting a set of features into a lower-dimensional subspace with PCA\n",
    "def project(features, dim):\n",
    "    standardized = StandardScaler().fit_transform(features)\n",
    "    pca = PCA(n_components=dim)\n",
    "    principalComponents = pca.fit_transform(X=standardized)\n",
    "    return principalComponents\n",
    "\n",
    "# Calculating the binomial proportion confidence interval\n",
    "def wilson(p, n, z = 1.96):\n",
    "    denominator = 1 + z**2/n\n",
    "    centre_adjusted_probability = p + z*z / (2*n)\n",
    "    adjusted_standard_deviation = sqrt((p*(1 - p) + z*z / (4*n)) / n)\n",
    "    \n",
    "    lower_bound = (centre_adjusted_probability - z*adjusted_standard_deviation) / denominator\n",
    "    upper_bound = (centre_adjusted_probability + z*adjusted_standard_deviation) / denominator\n",
    "    return (lower_bound, upper_bound)\n",
    "\n",
    "def country_to_iso3(country):\n",
    "    missing = {'South+Korea': 'KOR',\n",
    "            'North+Korea': 'PRK',\n",
    "            'Laos': 'LAO',\n",
    "            'Caribbean+Netherlands': 'BES',\n",
    "            'St.+Lucia': 'LCA',\n",
    "            'East+Timor': 'TLS',\n",
    "            'Democratic+Republic+of+Congo': 'COD',\n",
    "            'Swaziland': 'SWZ',\n",
    "            'Cape+Verde': 'CPV',\n",
    "            'C%C3%B4te+d%C2%B4Ivoire': 'CIV',\n",
    "            'Ivory+Coast': 'CIV',\n",
    "            'Channel+Islands': 'GBR'\n",
    "            }\n",
    "    try:\n",
    "        iso3 = pycountry.countries.search_fuzzy(country.replace('+', ' '))[0].alpha_3\n",
    "    except LookupError:\n",
    "        try:\n",
    "            iso3 = missing[country]\n",
    "        except KeyError:\n",
    "            iso3 = None\n",
    "    return iso3\n",
    "\n",
    "def display_filepaths(filepaths, width=100, height=100):\n",
    "    sidebyside = widgets.HBox([widgets.Image(value=open(filepath, 'rb').read(), format='png', width=width, height=height) for filepath in filepaths], layout=Layout(height='{}px'.format(height)))\n",
    "    display(sidebyside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Fill in below with dataset and file path names\n",
    "<a id=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([ \n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "dataset = datasets.YfccPlacesDataset(transform_train)\n",
    "folder_name = 'yfcc_supp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loc = '1_pager_geo'\n",
    "os.system(\"rm -r results/{0}/{1}\".format(folder_name, save_loc))\n",
    "file = folder(save_loc, folder_name)\n",
    "first_pass = True\n",
    "to_write = {}\n",
    "if not os.path.exists(\"checkpoints/{}\".format(folder_name)):\n",
    "    os.mkdir(\"checkpoints/{}\".format(folder_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# geo_ctr Metric: Country Counts\n",
    "<a id=\"geo_ctr\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "<a id=\"geo_ctr_setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True, toggle_text='Show/hide geo_ctr code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pickle.load(open(\"results/{}/geo_ctr.pkl\".format(folder_name), \"rb\"))\n",
    "iso3_to_subregion = pickle.load(open('util_files/iso3_to_subregion_mappings.pkl', 'rb'))\n",
    "gc = GeonamesCache()\n",
    "iso3_codes = list(gc.get_dataset_by_key(gc.get_countries(), 'iso3').keys())\n",
    "\n",
    "# https://ramiro.org/notebook/basemap-choropleth/\n",
    "cm = plt.get_cmap('Blues')\n",
    "bins = np.logspace(min(list(counts.values())), np.log2(max(list(counts.values()))+1), base=2.0)\n",
    "num_colors = len(bins)\n",
    "scheme = [cm(i / num_colors) for i in range(num_colors)]\n",
    "\n",
    "subregion_counts = {}\n",
    "iso3_to_bin = {}\n",
    "total = sum(counts.values())\n",
    "country_count_phrases = []\n",
    "iso3_to_scaledpop = {}\n",
    "\n",
    "for country in ['England', 'Scotland', 'Wales', 'Northern+Ireland']:\n",
    "    if country in counts.keys():\n",
    "        counts['United+Kingdom'] += counts[country]\n",
    "    counts.pop(country, None)\n",
    "\n",
    "for country, count in sorted(counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    country_count_phrases.append(\"{0}: {1}   {2}%\".format(country, count, round(100.*count/total)))\n",
    "    iso3 = country_to_iso3(country)\n",
    "    if iso3 is not None:\n",
    "        iso3_to_bin[iso3] = np.digitize(count, bins)\n",
    "        try:\n",
    "            iso3_to_scaledpop[iso3] = count / CountryInfo(country.replace('+', ' ')).population()\n",
    "        except KeyError:\n",
    "            pass\n",
    "#             print(\"{} not found in CountryInfo\".format(country))\n",
    "    try:\n",
    "        subregion = iso3_to_subregion[iso3]\n",
    "        if subregion in subregion_counts.keys():\n",
    "            subregion_counts[subregion] += count\n",
    "        else:\n",
    "            subregion_counts[subregion] = count\n",
    "    except KeyError:\n",
    "        print(\"This country's subregion not found: {}\".format(country))\n",
    "\n",
    "for key in iso3_to_scaledpop.keys():\n",
    "    iso3_to_scaledpop[key] /= min(iso3_to_scaledpop.values())\n",
    "\n",
    "def country_counts_num(topn):\n",
    "    print(\"Total images: {}\\n\".format(total))\n",
    "    print(\"Country Counts\\n\")\n",
    "    \n",
    "    print(\"Top:\\n\")\n",
    "    for i in range(topn):\n",
    "        print(country_count_phrases[i])\n",
    "    \n",
    "    print(\"\\nBottom:\\n\")\n",
    "    for i in range(topn):\n",
    "        print(country_count_phrases[-1-i])\n",
    "         \n",
    "def subregion_counts_num():\n",
    "    print(\"Subregion Counts\\n\")\n",
    "    total_subregion = sum(subregion_counts.values())\n",
    "    for subregion, count in sorted(subregion_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(\"{0}: {1}    {2}%\".format(subregion, count, round(100.*count/total_subregion)))\n",
    "\n",
    "def country_map():\n",
    "    fig = plt.figure(figsize=(16, 7))\n",
    "\n",
    "    fontsize = 20\n",
    "    ax = fig.add_subplot(111, facecolor='w', frame_on=False)\n",
    "    fig.suptitle('Dataset representation by number of images', fontsize=fontsize, y=.95)\n",
    "\n",
    "    m = Basemap(lon_0=0, projection='robin')\n",
    "    m.drawmapboundary(color='w')\n",
    "\n",
    "    shapefile = 'util_files/ne_10m_admin_0_countries_lakes'\n",
    "\n",
    "    m.readshapefile(shapefile, 'units', color='#444444', linewidth=.2)\n",
    "    for info, shape in zip(m.units_info, m.units):\n",
    "        iso3 = info['ADM0_A3']\n",
    "        if iso3 not in iso3_to_bin.keys():\n",
    "            color = '#dddddd'\n",
    "        else:\n",
    "            try:\n",
    "                color = scheme[iso3_to_bin[iso3]]\n",
    "            except IndexError:\n",
    "                print(iso3)\n",
    "                print(\"this index: {0} when length is {1}\".format(iso3_to_bin[iso3], len(scheme)))\n",
    "\n",
    "\n",
    "        patches = [Polygon(np.array(shape), True)]\n",
    "        pc = PatchCollection(patches)\n",
    "        pc.set_facecolor(color)\n",
    "        ax.add_collection(pc)\n",
    "\n",
    "    # Cover up Antarctica so legend can be placed over it.\n",
    "    ax.axhspan(0, 1000 * 1800, facecolor='w', edgecolor='w', zorder=2)\n",
    "\n",
    "    # Draw color legend.\n",
    "    ax_legend = fig.add_axes([0.35, 0.14, 0.3, 0.03], zorder=3)\n",
    "    cmap = mpl.colors.ListedColormap(scheme)\n",
    "    cb = mpl.colorbar.ColorbarBase(ax_legend, cmap=cmap, ticks=bins, boundaries=bins, orientation='horizontal')\n",
    "    #cb = mpl.colorbar.ColorbarBase(ax_legend, cmap=cmap, ticks=bins, boundaries=bins, orientation='vertical')\n",
    "    spots = len(bins) // 4\n",
    "    spots = [0, spots, spots*2, spots*3, len(bins)- 1]\n",
    "    cb.ax.set_xticklabels([str(round(int(i), -3)) if j in spots else '' for j, i in enumerate(bins)])\n",
    "    cb.ax.tick_params(labelsize=fontsize)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Total countries: {}\".format(len(iso3_to_bin)))\n",
    "\n",
    "def country_map_population():\n",
    "    fig = plt.figure(figsize=(16, 7))\n",
    "\n",
    "    fontsize = 20\n",
    "    ax = fig.add_subplot(111, facecolor='w', frame_on=False)\n",
    "\n",
    "    m = Basemap(lon_0=0, projection='robin')\n",
    "    m.drawmapboundary(color='w')\n",
    "\n",
    "    shapefile = 'util_files/ne_10m_admin_0_countries_lakes'\n",
    "    \n",
    "    cm = plt.get_cmap('Blues')\n",
    "    bins = np.logspace(min(list(iso3_to_scaledpop.values())), np.log2(max(list(iso3_to_scaledpop.values()))+1.), base=2.0)\n",
    "    num_colors = len(bins)\n",
    "    scheme = [cm(i / num_colors) for i in range(num_colors)]\n",
    "\n",
    "    m.readshapefile(shapefile, 'units', color='#444444', linewidth=.2)\n",
    "    for info, shape in zip(m.units_info, m.units):\n",
    "        iso3 = info['ADM0_A3']\n",
    "        if iso3 not in iso3_to_scaledpop.keys():\n",
    "            color = '#dddddd'\n",
    "        else:\n",
    "            try:\n",
    "                color = scheme[np.digitize(iso3_to_scaledpop[iso3], bins)]\n",
    "            except IndexError:\n",
    "                print(iso3)\n",
    "                print(\"this index: {0} when length is {1}\".format(iso3_to_bin[iso3], len(scheme)))\n",
    "\n",
    "\n",
    "        patches = [Polygon(np.array(shape), True)]\n",
    "        pc = PatchCollection(patches)\n",
    "        pc.set_facecolor(color)\n",
    "        ax.add_collection(pc)\n",
    "\n",
    "    ax.axhspan(0, 1000 * 1800, facecolor='w', edgecolor='w', zorder=2)\n",
    "\n",
    "    to_write[0] = ['(geo_ctr) Geographic representation of dataset scaled by country population, colored on a logarithmic scale.']\n",
    "    plt.savefig(\"results/{0}/{1}/0.png\".format(folder_name, save_loc), bbox_inches='tight', pad_inches=.2)\n",
    "    fig.suptitle('Dataset representation scaled by country population, logarithmic scale', fontsize=fontsize, y=.95)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses\n",
    "<a id=\"geo_ctr_analyses\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(country_counts_num, topn=widgets.IntSlider(min=1, max=30, step=1, value=10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts by subregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subregion_counts_num()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of representation by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of representation by country, scaled by population. Logarithmic scale. Some countries may be grayed out because the population could not be found for that country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_map_population()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# geo_tag Metric: Image Tags\n",
    "<a id=\"geo_tag\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "<a id=\"geo_tag_setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True, toggle_text='Show/hide geo_tag code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"results/{0}/6\".format(folder_name)):\n",
    "    os.mkdir(\"results/{0}/6\".format(folder_name))\n",
    "info_stats = pickle.load(open(\"results/{}/geo_tag.pkl\".format(folder_name), \"rb\")) #20GB\n",
    "country_tags = info_stats['country_tags']\n",
    "tag_to_subregion_features = info_stats['tag_to_subregion_features']\n",
    "iso3_to_subregion = pickle.load(open('util_files/iso3_to_subregion_mappings.pkl', 'rb'))\n",
    "categories = dataset.categories\n",
    "total_counts = np.zeros(len(categories))\n",
    "subregion_tags = {}\n",
    "for country, counts in country_tags.items():\n",
    "    total_counts = np.add(total_counts, counts)\n",
    "    subregion = iso3_to_subregion[country_to_iso3(country)]\n",
    "    if subregion not in subregion_tags.keys():\n",
    "        subregion_tags[subregion] = np.zeros(len(categories))\n",
    "    subregion_tags[subregion] = np.add(subregion_tags[subregion], counts)\n",
    "total_counts = total_counts.astype(int)\n",
    "sum_total_counts = int(np.sum(total_counts))\n",
    "if not os.path.exists('checkpoints/{}/6_a.pkl'.format(folder_name)):\n",
    "    pvalues_over = {} # pvalue : '[country]: [tag] (country num and total num info for now)'\n",
    "    pvalues_under = {} \n",
    "    for country, counts in country_tags.items():\n",
    "        tags_for_country = int(np.sum(counts))\n",
    "        if tags_for_country < 50: # threshold for country to have at least 50 tags so there are enough samples for analysis\n",
    "            continue\n",
    "        for i, count in enumerate(counts):\n",
    "            this_counts = np.zeros(tags_for_country)\n",
    "            this_counts[:int(count)] = 1\n",
    "            that_counts = np.zeros(sum_total_counts - tags_for_country)\n",
    "            that_counts[:total_counts[i] - int(count)] = 1\n",
    "            p = stats.ttest_ind(this_counts, that_counts)[1]\n",
    "            tag_info = '{0}-{1} ({2}/{3} vs {4}/{5})'.format(country, categories[i], int(count), tags_for_country, int(total_counts[i] - count), sum_total_counts - tags_for_country)\n",
    "            if np.mean(this_counts) > np.mean(that_counts):\n",
    "                pvalues_over[p] = tag_info\n",
    "            else:\n",
    "                pvalues_under[p] = tag_info\n",
    "else:\n",
    "    pvalues_under, pvalues_over = pickle.load(open('checkpoints/{}/6_a.pkl'.format(folder_name), 'rb'))\n",
    "subregion_pvalues_over = {}\n",
    "subregion_pvalues_under = {}\n",
    "for subregion, counts in subregion_tags.items():\n",
    "    tags_for_subregion = int(np.sum(counts))\n",
    "    for i, count in enumerate(counts):\n",
    "        this_counts = np.zeros(tags_for_subregion)\n",
    "        this_counts[:int(count)] = 1\n",
    "        that_counts = np.zeros(sum_total_counts - tags_for_subregion)\n",
    "        that_counts[:total_counts[i] - int(count)] = 1\n",
    "        p = stats.ttest_ind(this_counts, that_counts)[1]\n",
    "        tag_info = '{0}-{1} ({2}/{3} vs {4}/{5})'.format(subregion, categories[i], int(count), tags_for_subregion, int(total_counts[i] - count), sum_total_counts - tags_for_subregion)\n",
    "        if np.mean(this_counts) > np.mean(that_counts):\n",
    "            subregion_pvalues_over[p] = tag_info\n",
    "        else:\n",
    "            subregion_pvalues_under[p] = tag_info\n",
    "\n",
    "def tag_rep_by_country(topn):\n",
    "    if first_pass:\n",
    "        to_write[1] = [\"(geo_tag) Overrepresentations of tags by country (tag in country vs tag in rest of the countries):\"]\n",
    "        for p, content in sorted(pvalues_over.items(), key=lambda x: x[0])[:4]:\n",
    "            to_write[1].append(('{0}: {1}'.format(round(p, 4), content)))\n",
    "        to_write[1].append(\"\")\n",
    "        to_write[1].append(\"Underrepresentations of tags by country (tag in country vs tag in rest of the countries):\")\n",
    "        for p, content in sorted(pvalues_under.items(), key=lambda x: x[0])[:4]:\n",
    "            to_write[1].append(('{0}: {1}'.format(round(p, 4), content)))\n",
    "        \n",
    "    print(\"By Country\\n\")\n",
    "    print('Over represented\\n')\n",
    "    for p, content in sorted(pvalues_over.items(), key=lambda x: x[0])[:topn]:\n",
    "        print('{0}: {1}'.format(round(p, 4), content))\n",
    "    print('\\nUnder represented\\n')\n",
    "    for p, content in sorted(pvalues_under.items(), key=lambda x: x[0])[:topn]:\n",
    "        print('{0}: {1}'.format(round(p, 4), content))\n",
    "\n",
    "def tag_rep_by_subregion(topn):\n",
    "    print(\"By Subregion\\n\")\n",
    "    print('Over represented\\n')\n",
    "    for p, content in sorted(subregion_pvalues_over.items(), key=lambda x: x[0])[:topn]:\n",
    "       print('{0}: {1}'.format(round(p, 4), content))\n",
    "    print('\\nUnder represented\\n')\n",
    "    for p, content in sorted(subregion_pvalues_under.items(), key=lambda x: x[0])[:topn]:\n",
    "       print('{0}: {1}'.format(round(p, 4), content))\n",
    "\n",
    "if not os.path.exists('checkpoints/{}/6_b.pkl'.format(folder_name)):\n",
    "    phrase_to_value = {}\n",
    "    # Look at appearance differences in how a tag is represented across subregions\n",
    "    for tag in tag_to_subregion_features.keys():\n",
    "        subregion_features = tag_to_subregion_features[tag]\n",
    "        all_subregions = list(subregion_features.keys())\n",
    "        all_features = []\n",
    "        all_filepaths = []\n",
    "        start = 0\n",
    "        for subregion in all_subregions:\n",
    "            this_features = [features[0] for features in subregion_features[subregion]]\n",
    "            this_filepaths = [features[1] for features in subregion_features[subregion]]\n",
    "            if len(this_features) > 0:\n",
    "                all_features.append(np.array(this_features)[:, 0, :])\n",
    "                all_filepaths.append(this_filepaths)\n",
    "        if len(all_features) == 0:\n",
    "            continue\n",
    "        all_features = np.concatenate(all_features, axis=0)\n",
    "        all_filepaths = np.concatenate(all_filepaths, axis=0)\n",
    "        labels = np.zeros(len(all_features))\n",
    "        for j, subregion in enumerate(all_subregions):\n",
    "            labels[start:len(subregion_features[subregion])+start] = j\n",
    "            start += len(subregion_features[subregion])\n",
    "        num_features = int(np.sqrt(len(all_features)))\n",
    "        all_features = StandardScaler().fit_transform(project(all_features, num_features))\n",
    "\n",
    "        clf = svm.SVC(kernel='linear', probability=True, decision_function_shape='ovr', class_weight='balanced')\n",
    "\n",
    "        if len(np.unique(labels)) <= 1:\n",
    "            continue\n",
    "        clf.fit(all_features, labels)\n",
    "        acc = clf.score(all_features, labels)\n",
    "        probs = clf.decision_function(all_features)\n",
    "\n",
    "        labels = labels.astype(np.integer)\n",
    "        plot_kwds = {'alpha' : .8, 's' : 30, 'linewidths':0}\n",
    "        colorz = sns.color_palette('hls', int(np.amax(labels)) + 1)\n",
    "        projection_instances = TSNE().fit_transform(all_features)\n",
    "        plt.scatter(*projection_instances.T, **plot_kwds, c=[colorz[labels[i]] for i in range(len(all_features))])\n",
    "        handles = []\n",
    "        for lab in np.unique(labels):\n",
    "            patch = mpatches.Patch(color=colorz[lab], label=all_subregions[lab])\n",
    "            handles.append(patch)\n",
    "        fontP = FontProperties()\n",
    "        fontP.set_size('small')\n",
    "        lgd = plt.legend(handles=handles, bbox_to_anchor=(1.04,1), loc=\"upper left\", prop=fontP)\n",
    "        plt.savefig('results/{0}/{1}/{2}_tsne.png'.format(folder_name, 6, dataset.categories[tag]), bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        class_preds = clf.predict(all_features)\n",
    "        class_probs = clf.predict_proba(all_features)\n",
    "        j_to_acc = {}\n",
    "        for j, subregion in enumerate(all_subregions):\n",
    "            if j in labels:\n",
    "                # to get acc in subregion vs out\n",
    "                this_labels = np.copy(labels)\n",
    "                this_labels[np.where(labels!=j)[0]] = -1\n",
    "                this_preds = np.copy(class_preds)\n",
    "                this_preds[np.where(class_preds!=j)[0]] = -1\n",
    "                this_acc = np.mean(this_preds == this_labels)\n",
    "                j_to_acc[j] = this_acc\n",
    "\n",
    "        fig = plt.figure(figsize=(16, 12))\n",
    "        plt.subplots_adjust(hspace=.48)\n",
    "        fontsize = 24\n",
    "        diff_subregion = max(j_to_acc.items(), key=operator.itemgetter(1))[0]\n",
    "        subregion_index = list(clf.classes_).index(diff_subregion)\n",
    "        class_probs = class_probs[:, subregion_index]\n",
    "        in_sub = np.where(labels == diff_subregion)[0]\n",
    "        out_sub = np.where(labels != diff_subregion)[0]\n",
    "        in_probs = class_probs[in_sub]\n",
    "        out_probs = class_probs[out_sub]\n",
    "        in_indices = np.argsort(in_probs)\n",
    "        out_indices = np.argsort(out_probs)\n",
    "        \n",
    "        original_labels = np.copy(labels)\n",
    "\n",
    "        def subregion_scoring(estimator, X_test, y_test):\n",
    "            y_pred = estimator.predict(X_test)\n",
    "            y_test[np.where(y_test!=diff_subregion)[0]] = -1\n",
    "            y_pred[np.where(y_pred!=diff_subregion)[0]] = -1\n",
    "            acc_random = np.mean(y_test == y_pred)\n",
    "            return acc_random\n",
    "\n",
    "        base_acc, rand_acc, p_value = permutation_test_score(clf, all_features, labels, scoring=subregion_scoring, n_permutations=100)\n",
    "        value = base_acc/np.mean(rand_acc)\n",
    "        if p_value > .05 and value < 1.2: # can tune as desired\n",
    "            continue\n",
    "\n",
    "        phrase = dataset.labels_to_names[dataset.categories[tag]]\n",
    "        phrase_to_value[phrase] = [value, all_subregions[diff_subregion], acc, p_value, num_features, j_to_acc]\n",
    "        \n",
    "        pickle.dump([original_labels, class_probs, class_preds, diff_subregion, all_filepaths], open('results/{0}/{1}/{2}_info.pkl'.format(folder_name, 6, dataset.labels_to_names[dataset.categories[tag]]), 'wb'))\n",
    "    pickle.dump(phrase_to_value, open('checkpoints/{}/6_b.pkl'.format(folder_name), 'wb'))\n",
    "else:\n",
    "    phrase_to_value = pickle.load(open('checkpoints/{}/6_b.pkl'.format(folder_name), 'rb'))\n",
    "\n",
    "svm_options = []\n",
    "best_tag = None\n",
    "best_tag_value = 1.2\n",
    "for phrase, value in sorted(phrase_to_value.items(), key=lambda x: x[1][0], reverse=True):\n",
    "    value, region, acc, p_value, num_features, j_to_acc = phrase_to_value[phrase]\n",
    "    if acc > .75 and value > best_tag_value:\n",
    "        best_tag_value = value\n",
    "        best_tag = phrase\n",
    "    svm_options.append(('{0} in {1}: {2}% and {3}x'.format(phrase, region, round(100.*acc, 3), round(value, 3)), phrase))\n",
    "\n",
    "def show_svm_tag(tag, num):\n",
    "    if tag is None:\n",
    "        return\n",
    "    this_info = pickle.load(open('results/{0}/{1}/{2}_info.pkl'.format(folder_name, 6, tag), 'rb'))\n",
    "    labels, class_probs, class_preds, diff_subregion, all_filepaths = this_info\n",
    "    value, region, acc, p_value, num_features, j_to_acc = phrase_to_value[tag]\n",
    "    if num is not None:\n",
    "        print(\"{0} in {1} has acc: {2}, with p={3}, {4}x and {5} features\".format(tag, region, round(acc, 3), round(p_value, 3), round(value, 3), num_features))\n",
    "        print()\n",
    "    \n",
    "    in_sub = np.where(labels == diff_subregion)[0]\n",
    "    out_sub = np.where(labels != diff_subregion)[0]\n",
    "    in_probs = class_probs[in_sub]\n",
    "    out_probs = class_probs[out_sub]\n",
    "    in_indices = np.argsort(in_probs)\n",
    "    out_indices = np.argsort(out_probs)\n",
    "    \n",
    "    to_save = False\n",
    "    if num is None:\n",
    "        to_write[2] = ['(geo_tag) To discern if there is an appearance difference in how certain subregions represent a tag, we extract scene-level features from each image, and fit a linear SVM to distinguish between the tag in the subregion and out of the subregion.\\nAn example of the most linearly separable tag: {0} has an accuracy of {1} when classifying in {2} vs outside {2}.\\n'.format(tag, round(acc, 3), region)]\n",
    "        to_save = True\n",
    "        num = 5\n",
    "                \n",
    "    def display_chunk(in_subregion_label=True, in_subregion_pred=True, to_save=False, name=None):\n",
    "        subregion_filepaths = []\n",
    "        if in_subregion_label == in_subregion_pred:\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter = -1\n",
    "        while len(subregion_filepaths) < num:\n",
    "            try:\n",
    "                if in_subregion_label:\n",
    "                    index_a = in_sub[in_indices[counter]]\n",
    "                else:\n",
    "                    index_a = out_sub[out_indices[counter]]\n",
    "            except:\n",
    "                break\n",
    "            file_path_a = all_filepaths[index_a]\n",
    "            if (in_subregion_pred and class_preds[index_a] == diff_subregion) or ((not in_subregion_pred) and class_preds[index_a] != diff_subregion):\n",
    "                subregion_filepaths.append(file_path_a)\n",
    "            if in_subregion_label == in_subregion_pred:\n",
    "                counter += 1\n",
    "            else:\n",
    "                counter -= -1\n",
    "        if to_save and first_pass:\n",
    "            this_loc = \"results/{0}/{1}/1_{2}.png\".format(folder_name, save_loc, name)\n",
    "            if len(subregion_filepaths) > 0:\n",
    "                fig = plt.figure(figsize=(16, 8))\n",
    "                for i in range(num):\n",
    "                    ax = fig.add_subplot(1, num, i+1)\n",
    "                    ax.axis(\"off\")\n",
    "                    if i >= len(subregion_filepaths):\n",
    "                        image = np.ones((3, 3, 3))\n",
    "                    else:\n",
    "                        image, _ = dataset.from_path(subregion_filepaths[i])\n",
    "                        image = image.data.cpu().numpy().transpose(1, 2, 0)\n",
    "                    im = ax.imshow(image, extent=SAME_EXTENT)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(this_loc, bbox_inches='tight')\n",
    "                plt.close()\n",
    "            else:\n",
    "                os.system(\"cp util_files/no_images.png {0}\".format(this_loc))\n",
    "        elif len(subregion_filepaths) > 0:\n",
    "            display_filepaths(subregion_filepaths, width = 800//len(subregion_filepaths), height=800//len(subregion_filepaths))\n",
    "        else:\n",
    "            print(\"No images in this category\")\n",
    "    if not to_save:\n",
    "        print(\"In: Correct\")\n",
    "    else:\n",
    "        to_write[2].append(\"In: Correct\")\n",
    "    display_chunk(True, True, to_save, 'a')\n",
    "    if not to_save:\n",
    "        print(\"In: Incorrect\")\n",
    "    else:\n",
    "        to_write[2].append(\"In: Incorrect\")\n",
    "    display_chunk(True, False, to_save, 'b')\n",
    "    if not to_save:\n",
    "        print(\"Out: Incorrect\")\n",
    "    else:\n",
    "        to_write[2].append(\"Out: Incorrect\")\n",
    "    display_chunk(False, True, to_save, 'c')\n",
    "    if not to_save:\n",
    "        print(\"Out: Correct\")\n",
    "    else:\n",
    "        to_write[2].append(\"Out: Correct\")\n",
    "    display_chunk(False, False, to_save, 'd')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses \n",
    "<a id=\"geo_tag_analyses\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over- and under- representations of tags by country. The first fraction shows how many of this country's tags are made up of this one, and the second fraction shows how many of all of the country's tags are made up of this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(tag_rep_by_country, topn=widgets.IntSlider(min=1, max=30, step=1, value=10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over- and under- representations of tags by subregion, fractions represent same thing as mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(tag_rep_by_subregion, topn=widgets.IntSlider(min=1, max=30, step=1, value=10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How linearly separable images with a particular tag are in one subregion compared to the rest.\n",
    "The percentage in the dropdown menu indicates the accuracy of the classifier at distinguishing this subregion from the others, and the ratio represents test accuracy over that of random labels. The p-value is provided using the permutation test and gives a sense of how well the classifier exploits dependancies between features and labels (as opposed to overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_widget = widgets.IntSlider(min=1, max=20, step=1, value=5)\n",
    "tag_widget = widgets.Dropdown(options=svm_options, layout=Layout(width='400px'))\n",
    "all_things = [widgets.Label('Tag, acc, acc/acc_random',layout=Layout(padding='0px 0px 0px 5px', width='170px')), tag_widget, widgets.Label('Num',layout=Layout(padding='0px 5px 0px 40px', width='80px')), num_widget]\n",
    "\n",
    "if first_pass:\n",
    "    show_svm_tag(best_tag, None)\n",
    "ui = HBox(all_things)\n",
    "out = widgets.interactive_output(show_svm_tag, {'tag': tag_widget, 'num': num_widget})\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# geo_lng Metric: Languages for tourist vs local\n",
    "<a id=\"geo_lng\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "<a id=\"metric10_setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True, toggle_text='Show/hide geo_lng code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso3_to_subregion = pickle.load(open('util_files/iso3_to_subregion_mappings.pkl', 'rb'))\n",
    "mappings = pickle.load(open('util_files/country_lang_mappings.pkl', 'rb'))\n",
    "iso3_to_lang = mappings['iso3_to_lang']\n",
    "lang_to_iso3 = mappings['lang_to_iso3']\n",
    "\n",
    "lang_info = pickle.load(open('results/{}/geo_lng.pkl'.format(folder_name), 'rb'))\n",
    "counts = lang_info['lang_counts']\n",
    "country_with_langs = lang_info['country_with_langs']\n",
    "country_with_imgs = lang_info['country_with_imgs']\n",
    "\n",
    "gc = GeonamesCache()\n",
    "iso3_codes = list(gc.get_dataset_by_key(gc.get_countries(), 'iso3').keys())\n",
    "\n",
    "cm = plt.get_cmap('Blues')\n",
    "iso3_to_counts = {}\n",
    "iso3_to_bin = {}\n",
    "total = sum(counts.values())\n",
    "langcount_phrases = []\n",
    "for lang, count in sorted(counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    lang_name = pycountry.languages.get(alpha_2=lang)\n",
    "    if lang_name is not None:\n",
    "        lang_name = lang_name.name\n",
    "    else:\n",
    "        lang_name = lang\n",
    "    langcount_phrases.append(\"{0}: {1}   {2}%\".format(lang_name, count, round(count*100./total, 4)))\n",
    "    try:\n",
    "        for iso3 in lang_to_iso3[lang]:\n",
    "            if iso3 not in iso3_to_counts.keys():\n",
    "                iso3_to_counts[iso3] = count\n",
    "            else:\n",
    "                iso3_to_counts[iso3] += count\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "bins = np.logspace(min(list(iso3_to_counts.values())), np.log2(max(list(iso3_to_counts.values()))+1), base=2.0)\n",
    "num_colors = len(bins)\n",
    "scheme = [cm(i / num_colors) for i in range(num_colors)]\n",
    "\n",
    "for key in iso3_to_counts.keys():\n",
    "    iso3_to_bin[key] = np.digitize(iso3_to_counts[key], bins) - 1\n",
    "\n",
    "def language_representation_map():\n",
    "    fig = plt.figure(figsize=(12, 7))\n",
    "    fontsize = 14\n",
    "\n",
    "    ax = fig.add_subplot(111, facecolor='w', frame_on=False)\n",
    "    fig.suptitle('Dataset representation by tag language for images', fontsize=fontsize, y=.95)\n",
    "\n",
    "    m = Basemap(lon_0=0, projection='robin')\n",
    "    m.drawmapboundary(color='w')\n",
    "\n",
    "    shapefile = 'util_files/ne_10m_admin_0_countries_lakes'\n",
    "\n",
    "    m.readshapefile(shapefile, 'units', color='#444444', linewidth=.2)\n",
    "    for info, shape in zip(m.units_info, m.units):\n",
    "        iso3 = info['ADM0_A3']\n",
    "        if iso3 not in iso3_to_bin.keys():\n",
    "            color = '#dddddd'\n",
    "        else:\n",
    "            try:\n",
    "                color = scheme[iso3_to_bin[iso3]]\n",
    "            except IndexError:\n",
    "                pass\n",
    "\n",
    "        patches = [Polygon(np.array(shape), True)]\n",
    "        pc = PatchCollection(patches)\n",
    "        pc.set_facecolor(color)\n",
    "        ax.add_collection(pc)\n",
    "\n",
    "    # Cover up Antarctica so legend can be placed over it.\n",
    "    ax.axhspan(0, 1000 * 1800, facecolor='w', edgecolor='w', zorder=2)\n",
    "\n",
    "    # Draw color legend.\n",
    "    ax_legend = fig.add_axes([0.35, 0.14, 0.3, 0.03], zorder=3)\n",
    "    cmap = mpl.colors.ListedColormap(scheme)\n",
    "    cb = mpl.colorbar.ColorbarBase(ax_legend, cmap=cmap, ticks=bins, boundaries=bins, orientation='horizontal')\n",
    "    spots = len(bins) // 4\n",
    "    spots = [0, spots, spots*2, spots*3, len(bins)- 1]\n",
    "    cb.ax.set_xticklabels([str(int(i)) if j in spots else '' for j, i in enumerate(bins)])\n",
    "    cb.ax.tick_params(labelsize=fontsize)\n",
    "    plt.show()\n",
    "\n",
    "def language_counts(topn):\n",
    "    if first_pass:\n",
    "        to_write[3] = ['(geo_lng) Most popular languages:']\n",
    "        for i in range(3):\n",
    "            to_write[3].append(langcount_phrases[i])\n",
    "    print(\"Most popular languages\\n\")\n",
    "    for i in range(topn):\n",
    "        print(langcount_phrases[i])\n",
    "    \n",
    "    print(\"\\nLeast popular languages\\n\")\n",
    "    for i in range(topn):\n",
    "        print(langcount_phrases[-1-i])\n",
    "        \n",
    "to_write_lower = {}\n",
    "to_write_upper = {}\n",
    "iso3_to_percent = {}\n",
    "subregion_to_percents = {}\n",
    "subregion_to_filepaths = {} # 0 is tourist, 1 is local\n",
    "subregion_to_embeddings = {} # 0 is tourist, 1 is local\n",
    "for country in country_with_langs.keys():\n",
    "    iso3 = country_to_iso3(country)\n",
    "    langs_in = 0\n",
    "    langs_out = {}\n",
    "    for lang in country_with_langs[country]:\n",
    "        try:\n",
    "            if lang in iso3_to_lang[iso3]:\n",
    "                langs_in += 1\n",
    "            else:\n",
    "                if lang in langs_out.keys():\n",
    "                    langs_out[lang] += 1\n",
    "                else:\n",
    "                    langs_out[lang] = 1\n",
    "        except KeyError:\n",
    "             print(\"This iso3 can't be found in iso3_to_lang: {}\".format(iso3))\n",
    "    this_total = len(country_with_langs[country])\n",
    "    others = ''\n",
    "    for lang in langs_out.keys():\n",
    "        if len(lang) == 2:\n",
    "            lang_name = pycountry.languages.get(alpha_2=lang)\n",
    "        elif len(lang) == 3:\n",
    "            lang_name = pycountry.languages.get(alpha_3=lang)\n",
    "        else:\n",
    "            print(\"{} is not 2 or 3 letters?\".format(lang))\n",
    "        if lang_name is not None:\n",
    "            lang_name = lang_name.name\n",
    "        else:\n",
    "            lang_name = lang\n",
    "        others += lang_name + \": \" + str(round(langs_out[lang]/this_total, 4)) + \", \"\n",
    "    if iso3 is not None:\n",
    "        subregion = iso3_to_subregion[iso3]\n",
    "        if subregion in subregion_to_percents.keys():\n",
    "            subregion_to_percents[subregion][0] += langs_in\n",
    "            subregion_to_percents[subregion][1] += this_total\n",
    "            subregion_to_filepaths[subregion][0].extend([chunk[1] for chunk in country_with_imgs[country][0]])\n",
    "            subregion_to_filepaths[subregion][1].extend([chunk[1] for chunk in country_with_imgs[country][1]])\n",
    "            subregion_to_embeddings[subregion][0].extend([chunk[0] for chunk in country_with_imgs[country][0]])\n",
    "            subregion_to_embeddings[subregion][1].extend([chunk[0] for chunk in country_with_imgs[country][1]])\n",
    "        else:\n",
    "            subregion_to_percents[subregion] = [langs_in, this_total]\n",
    "            subregion_to_filepaths[subregion] = [[chunk[1] for chunk in country_with_imgs[country][0]], [chunk[1] for chunk in country_with_imgs[country][1]]]\n",
    "            subregion_to_embeddings[subregion] = [[chunk[0] for chunk in country_with_imgs[country][0]], [chunk[0] for chunk in country_with_imgs[country][1]]]\n",
    "    tourist_percent = 1.0 - (langs_in / this_total)\n",
    "    lp_under, lp_over = wilson(tourist_percent, this_total)\n",
    "    phrase = '{0} has {1}% non-local tags, and the extra tags are:\\n\\n{2}'.format(country, round(100.*tourist_percent, 4), others)\n",
    "    to_write_lower[country] = [phrase, tourist_percent]\n",
    "    iso3_to_percent[iso3] = lp_under\n",
    "\n",
    "def lang_dist_by_country(country):\n",
    "    print(to_write_lower[country][0][:-2])\n",
    "\n",
    "subregion_to_accuracy = {}\n",
    "subregion_to_percents_phrase = {}\n",
    "for key in subregion_to_percents.keys():\n",
    "    if not os.path.exists('results/{0}/{1}/{2}_info.pkl'.format(folder_name, 10, key.replace(' ', '_'))):\n",
    "        low_bound, high_bound = wilson(1 - subregion_to_percents[key][0] / subregion_to_percents[key][1], subregion_to_percents[key][1])\n",
    "\n",
    "        clf = svm.SVC(kernel='linear', probability=False, decision_function_shape='ovr', class_weight='balanced')\n",
    "        clf_random = svm.SVC(kernel='linear', probability=False, decision_function_shape='ovr', class_weight='balanced')\n",
    "        tourist_features = subregion_to_embeddings[key][0]\n",
    "        local_features = subregion_to_embeddings[key][1]\n",
    "        if len(tourist_features) == 0 or len(local_features) == 0:\n",
    "            continue\n",
    "        tourist_features, local_features = np.array(tourist_features)[:, 0, :], np.array(local_features)[:, 0, :]\n",
    "        all_features = np.concatenate([tourist_features, local_features], axis=0)\n",
    "        num_features = int(np.sqrt(len(all_features)))\n",
    "        all_features = project(all_features, num_features)\n",
    "        labels = np.zeros(len(all_features))\n",
    "        labels[len(tourist_features):] = 1\n",
    "        clf.fit(all_features, labels)\n",
    "        acc = clf.score(all_features, labels)\n",
    "        probs = clf.decision_function(all_features)\n",
    "\n",
    "        np.random.shuffle(all_features)\n",
    "        clf_random.fit(all_features, labels)\n",
    "        acc_random = clf_random.score(all_features, labels)\n",
    "        value = acc / acc_random\n",
    "\n",
    "        subregion_to_percents_phrase[key] = [subregion_to_percents[key][0] / subregion_to_percents[key][1], '[{0} - {1}] for {2}'.format(round(low_bound, 4), round(high_bound, 4), subregion_to_percents[key][1])]\n",
    "        subregion_to_accuracy[key] = [acc, value, len(tourist_features), len(all_features), num_features]\n",
    "        tourist_probs = []\n",
    "        local_probs = []\n",
    "        for j in range(len(all_features)):\n",
    "            if j < len(tourist_features):\n",
    "                tourist_probs.append(-probs[j])\n",
    "            else:\n",
    "                local_probs.append(probs[j])        \n",
    "        pickle.dump([labels, tourist_probs, local_probs, subregion_to_filepaths[key]], open('results/{0}/{1}/{2}_info.pkl'.format(folder_name, 10, key.replace(' ', '_')), 'wb'))\n",
    "subregion_local_svm_loc = 'results/{0}/{1}/subregion_svm.pkl'.format(folder_name, 10)\n",
    "if not os.path.exists(subregion_local_svm_loc):\n",
    "    pickle.dump([subregion_to_accuracy, subregion_to_percents_phrase], open(subregion_local_svm_loc, 'wb'))\n",
    "\n",
    "def subregion_language_analysis(key, num):\n",
    "    to_save = False\n",
    "    acc, value, num_tourists, num_total, num_features = pickle.load(open(subregion_local_svm_loc, 'rb'))[0][key]\n",
    "    print_statement = \"Accuracy: {0}%, {1}x with {2} features. {3} out of {4} are tourist\".format(round(acc*100., 3), round(value, 3), num_features, num_tourists, num_total)\n",
    "    if num is None:\n",
    "        to_save = True\n",
    "        num = 5\n",
    "        to_write[4] = [\"(geo_lng) Subregion that is most linearly separable between locals and tourists.\"]\n",
    "        to_write[4].append(print_statement)\n",
    "    else:\n",
    "        print(print_statement)\n",
    "\n",
    "    labels, tourist_probs, local_probs, the_filepaths = pickle.load(open('results/{0}/{1}/{2}_info.pkl'.format(folder_name, 10, key.replace(' ', '_')), 'rb'))\n",
    "    \n",
    "    tourist_indices = np.argsort(np.array(tourist_probs))\n",
    "    local_indices = np.argsort(np.array(local_probs))\n",
    "    \n",
    "    the_indices = [tourist_indices, local_indices]\n",
    "    the_probs = [tourist_probs, local_probs]\n",
    "    \n",
    "    def display_chunk(local=0, correct=True, to_save=False, name=None):\n",
    "        this_filepaths = the_filepaths[local]\n",
    "        this_indices = the_indices[local]\n",
    "        this_probs = the_probs[local]\n",
    "        collected_filepaths = []\n",
    "        \n",
    "        if correct:\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter = -1\n",
    "        while len(collected_filepaths) < num:\n",
    "            try:\n",
    "                index_a = this_indices[counter]\n",
    "            except:\n",
    "                break\n",
    "            file_path_a = this_filepaths[index_a]\n",
    "            if (this_probs[index_a] > 0 and correct) or (this_probs[index_a] < 0 and not correct):\n",
    "                collected_filepaths.append(file_path_a)\n",
    "            if correct:\n",
    "                counter += 1\n",
    "            else:\n",
    "                counter -= -1\n",
    "        if to_save and first_pass:\n",
    "            this_loc = \"results/{0}/{1}/2_{2}.png\".format(folder_name, save_loc, name)\n",
    "            if len(collected_filepaths) > 0:\n",
    "                fig = plt.figure(figsize=(16, 8))\n",
    "                for i in range(num):\n",
    "                    ax = fig.add_subplot(1, num, i+1)\n",
    "                    ax.axis(\"off\")\n",
    "                    if i >= len(collected_filepaths):\n",
    "                        image = np.ones((3, 3, 3))\n",
    "                    else:\n",
    "                        image, _ = dataset.from_path(collected_filepaths[i])\n",
    "                        image = image.data.cpu().numpy().transpose(1, 2, 0)\n",
    "                    im = ax.imshow(image, extent=SAME_EXTENT)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(this_loc, bbox_inches = 'tight')\n",
    "                plt.close()\n",
    "            else:\n",
    "                os.system(\"cp util_files/no_images.png {}\".format(this_loc))\n",
    "        elif len(collected_filepaths) > 0:\n",
    "            display_filepaths(collected_filepaths, width = 800//len(collected_filepaths), height=800//len(collected_filepaths))\n",
    "        else:\n",
    "            print(\"No images in this category\")\n",
    "    if not to_save:\n",
    "        print(\"Tourist: Correct\")\n",
    "    else:\n",
    "        to_write[4].append(\"Tourist: Correct\")\n",
    "    display_chunk(0, True, to_save, 'a')\n",
    "    if not to_save:\n",
    "        print(\"Tourist: Incorrect\")\n",
    "    else:\n",
    "        to_write[4].append(\"Tourist: Incorrect\")\n",
    "    display_chunk(0, False, to_save, 'b')\n",
    "    if not to_save:\n",
    "        print(\"Local: Incorrect\")\n",
    "    else:\n",
    "        to_write[4].append(\"Local: Incorrect\")\n",
    "    display_chunk(1, False, to_save, 'c')\n",
    "    if not to_save:\n",
    "        print(\"Local: Correct\")\n",
    "    else:\n",
    "        to_write[4].append(\"Local: Correct\")\n",
    "    display_chunk(1, True, to_save, 'd')\n",
    "\n",
    "subregion_to_accuracy, subregion_to_percents_phrase = pickle.load(open(subregion_local_svm_loc, 'rb'))\n",
    "subregion_svm_options = []\n",
    "most_different_subregion_value = 1.2\n",
    "most_different_subregion = None\n",
    "for subregion, value in sorted(subregion_to_accuracy.items(), key=lambda x: x[1][1], reverse=True):\n",
    "    acc, value, num_tourists, num_total, num_features = subregion_to_accuracy[subregion]\n",
    "    if acc > .75 and value > most_different_subregion_value:\n",
    "        most_different_subregion_value = value\n",
    "        most_different_subregion = subregion\n",
    "    subregion_svm_options.append(('{0}: {1}% and {2}x'.format(subregion, round(100.*acc, 3), round(value, 3)), subregion))\n",
    "    \n",
    "def non_local_lang_map():\n",
    "    iso3_to_bin = {}\n",
    "    num_colors = 20\n",
    "    cm = plt.get_cmap('Blues')\n",
    "    bins = np.linspace(0., 1., num_colors)\n",
    "\n",
    "    scheme = [cm(i / num_colors) for i in range(num_colors)]\n",
    "\n",
    "    for key in iso3_to_percent.keys():\n",
    "        iso3_to_bin[key] = np.digitize(iso3_to_percent[key], bins) - 1 # add a -1 here if np.linspace\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    fontsize = 20\n",
    "\n",
    "    ax = fig.add_subplot(111, facecolor='w', frame_on=False)\n",
    "    fig.suptitle('Percentage of tags in non-local language', fontsize=fontsize, y=.95)\n",
    "\n",
    "    m = Basemap(lon_0=0, projection='robin')\n",
    "    m.drawmapboundary(color='w')\n",
    "\n",
    "    shapefile = 'util_files/ne_10m_admin_0_countries_lakes'\n",
    "\n",
    "    m.readshapefile(shapefile, 'units', color='#444444', linewidth=.2)\n",
    "    for info, shape in zip(m.units_info, m.units):\n",
    "        iso3 = info['ADM0_A3']\n",
    "        if iso3 not in iso3_to_bin.keys():\n",
    "            color = '#dddddd'\n",
    "        else:\n",
    "            try:\n",
    "                color = scheme[iso3_to_bin[iso3]]\n",
    "            except IndexError:\n",
    "                print(iso3)\n",
    "                print(\"this index: {0} when length is {1}\".format(iso3_to_bin[iso3], len(scheme)))\n",
    "\n",
    "\n",
    "        patches = [Polygon(np.array(shape), True)]\n",
    "        pc = PatchCollection(patches)\n",
    "        pc.set_facecolor(color)\n",
    "        ax.add_collection(pc)\n",
    "\n",
    "    # Cover up Antarctica so legend can be placed over it.\n",
    "    ax.axhspan(0, 1000 * 1800, facecolor='w', edgecolor='w', zorder=2)\n",
    "\n",
    "    # Draw color legend.\n",
    "    ax_legend = fig.add_axes([0.35, 0.14, 0.3, 0.03], zorder=3)\n",
    "    cmap = mpl.colors.ListedColormap(scheme)\n",
    "    cb = mpl.colorbar.ColorbarBase(ax_legend, cmap=cmap, ticks=bins, boundaries=bins, orientation='horizontal')\n",
    "    spots = len(bins) // 3\n",
    "    spots = [0, spots, spots*2, len(bins)- 1]\n",
    "    cb.ax.set_xticklabels([str(round(i, 2)) if j in spots else '' for j, i in enumerate(bins)])\n",
    "    cb.ax.tick_params(labelsize=fontsize)\n",
    "    if first_pass:\n",
    "        plt.savefig(\"results/{0}/{1}/3.png\".format(folder_name, save_loc))\n",
    "        to_write[5] = [\"(geo_lng) Map representing the fraction of tags in a country that are not labeled in a local language.\"]\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses\n",
    "<a id=\"geo_lng_analyses\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map that for each language, contributes to the counts of all countries that have that language as a national language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_representation_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Languages represented in the dataset, as detected by FastText. 3 letter acronyms mean that we could not automatically find the language corresponding to the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(language_counts, topn=widgets.IntSlider(min=1, max=30, step=1, value=10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets you select a country, along with the fraction of images in that country that are tagged in a non-local language, to see what languages the tags are made up of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [('{0}: {1}'.format(country, round(value[1], 3)), country) for country, value in sorted(to_write_lower.items(), key=lambda x: x[1][1], reverse=True)]\n",
    "interact(lang_dist_by_country, country=widgets.Dropdown(options=pairs));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows the subregion and how accurately a linear model can separate images taken by locals vs tourists. Ratio is accuracy over that of randomly shuffled labels, as mentioned before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_sub_widget = widgets.IntSlider(min=1, max=20, step=1, value=5)\n",
    "key_widget = widgets.Dropdown(options=subregion_svm_options, layout=Layout(width='400px'))\n",
    "all_things = [widgets.Label('Tag, acc/acc_random, acc',layout=Layout(padding='0px 0px 0px 5px', width='170px')), key_widget, widgets.Label('Num',layout=Layout(padding='0px 5px 0px 40px', width='80px')), num_sub_widget]\n",
    "\n",
    "if first_pass and most_different_subregion is not None:\n",
    "    subregion_language_analysis(most_different_subregion, None)\n",
    "ui = HBox(all_things)\n",
    "out = widgets.interactive_output(subregion_language_analysis, {'key': key_widget, 'num': num_sub_widget})\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows for each country, the percentage of tags in a non-local language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_local_lang_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence bounds on fracion of each subregion's languages that are non-local, and number of images from that subregion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bounds on fraction of each subregion's languages that are non-local\")\n",
    "for subregion, percent in sorted(subregion_to_percents_phrase.items(), key=lambda x: x[1][0], reverse=True):\n",
    "    print(\"{0}: {1}\".format(subregion, percent[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up summary pdf\n",
    "<a id=\"summarypdf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pass = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pdf(numbers):\n",
    "    for i in numbers:\n",
    "        if i in to_write.keys():\n",
    "            if i not in [2, 4]:\n",
    "                for sentence in to_write[i]:\n",
    "                    pdf.write(5, sentence)\n",
    "                    pdf.ln()\n",
    "            if i == 0:\n",
    "                pdf.image('results/{0}/{1}/0.png'.format(folder_name, save_loc), h=80)\n",
    "                pdf.ln()\n",
    "            elif i == 2:\n",
    "                pdf.write(5, to_write[i][0])\n",
    "                pdf.ln()\n",
    "                pdf.write(5, to_write[i][1])\n",
    "                pdf.ln()\n",
    "                pdf.image('results/{0}/{1}/1_a.png'.format(folder_name, save_loc), w=160)\n",
    "                pdf.ln()\n",
    "                pdf.write(5, to_write[i][2])\n",
    "                pdf.ln()\n",
    "                pdf.image('results/{0}/{1}/1_b.png'.format(folder_name, save_loc), w=160)\n",
    "                pdf.ln()\n",
    "                pdf.write(5, to_write[i][3])\n",
    "                pdf.ln()\n",
    "                pdf.image('results/{0}/{1}/1_c.png'.format(folder_name, save_loc), w=160)\n",
    "                pdf.ln()\n",
    "                pdf.write(5, to_write[i][4])\n",
    "                pdf.ln()\n",
    "                pdf.image('results/{0}/{1}/1_d.png'.format(folder_name, save_loc), w=160)\n",
    "                pdf.ln()\n",
    "            elif i == 4:\n",
    "                pdf.write(5, to_write[i][0])\n",
    "                pdf.ln()\n",
    "                pdf.write(5, to_write[i][1])\n",
    "                pdf.ln()\n",
    "                pdf.write(5, to_write[i][2])\n",
    "                pdf.ln()\n",
    "                pdf.image('results/{0}/{1}/2_a.png'.format(folder_name, save_loc), w=160)\n",
    "                pdf.ln()\n",
    "                pdf.write(5, to_write[i][3])\n",
    "                pdf.ln()\n",
    "                pdf.image('results/{0}/{1}/2_b.png'.format(folder_name, save_loc), w=160)\n",
    "                pdf.ln()\n",
    "                pdf.write(5, to_write[i][4])\n",
    "                pdf.ln()\n",
    "                pdf.image('results/{0}/{1}/2_c.png'.format(folder_name, save_loc), w=160)\n",
    "                pdf.ln()\n",
    "                pdf.write(5, to_write[i][5])\n",
    "                pdf.ln()\n",
    "                pdf.image('results/{0}/{1}/2_d.png'.format(folder_name, save_loc), w=160)\n",
    "                pdf.ln()\n",
    "            elif i == 5:\n",
    "                pdf.image('results/{0}/{1}/3.png'.format(folder_name, save_loc), h=80)\n",
    "                pdf.ln()\n",
    "            pdf.ln(h=3)\n",
    "            pdf.dashed_line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "            pdf.ln(h=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fpdf import FPDF\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font('Arial', 'B', 16)\n",
    "pdf.write(5, \"Geography-Based Summary\")\n",
    "pdf.ln()\n",
    "pdf.ln()\n",
    "\n",
    "# Overview Statistics\n",
    "pdf.set_font('Arial', 'B', 12)\n",
    "pdf.write(5, \"Overview Statistics\")\n",
    "pdf.ln()\n",
    "pdf.ln(h=3)\n",
    "pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "pdf.ln(h=3)\n",
    "pdf.set_font('Arial', '', 12)\n",
    "write_pdf([0, 3, 5])\n",
    "\n",
    "# Interesting findings\n",
    "pdf.set_font('Arial', 'B', 12)\n",
    "pdf.write(5, \"Sample Interesting Findings\")\n",
    "pdf.ln()\n",
    "pdf.ln(h=3)\n",
    "pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "pdf.ln(h=3)\n",
    "pdf.set_font('Arial', '', 12)\n",
    "write_pdf([1, 2, 4])\n",
    "\n",
    "# Interesting findings\n",
    "pdf.set_font('Arial', 'B', 12)\n",
    "pdf.write(5, \"Some of the other metrics in the notebook\")\n",
    "pdf.ln()\n",
    "pdf.ln(h=3)\n",
    "pdf.line(10, pdf.get_y(), 200, pdf.get_y())\n",
    "pdf.ln(h=3)\n",
    "pdf.set_font('Arial', '', 12)\n",
    "pdf.write(5, \"- (geo_ctr) Image breakdown by country and subregion\")\n",
    "pdf.ln()\n",
    "pdf.write(5, \"- (geo_ctr) Dataset representation map\")\n",
    "pdf.ln()\n",
    "pdf.write(5, \"- (geo_tag) Over/under representations of tags by subregion\")\n",
    "pdf.ln()\n",
    "pdf.write(5, \"- (geo_lng) Visual representation of what languages are represented\")\n",
    "pdf.ln()\n",
    "pdf.write(5, \"- (geo_lng) What languages each country's tags are in\")\n",
    "pdf.ln()\n",
    "\n",
    "pdf.output('results/{0}/{1}/summary.pdf'.format(folder_name, save_loc), \"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
