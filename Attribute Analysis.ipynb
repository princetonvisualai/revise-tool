{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute Analysis\n",
    "The following notebook can analyze a given attribute with any number of expected values (2+), and will perform metrics 1,2,3,4,11 generalized to any attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "1. Fill in the dataset in section 1.1\n",
    "\n",
    "2. Run all of the cells\n",
    "\n",
    "3. Look at the summary pdf generated AND/OR explore each metric below.\n",
    "    - Under each Metric there will be a portion of \"Setup\" and then \"Analyses\". Ignore the \"Setup\" unless customization is needed, and in \"Analyses\" results are shown to be interacted with. The number that comes after the M in the title refers to the measurement number when collecting the metrics.\n",
    "    \n",
    "## Table of Contents\n",
    "1. [Initial Setup](#setup) <br/>\n",
    "    1.1 [Dataset](#dataset) <br/>\n",
    "2. (M1) Metric: [Distance from center, size, attribute label inference](#metric1)<br/>\n",
    "    2.1 [Setup](#metric1_setup)<br/>\n",
    "    2.2 [Analyses](#metric1_analyses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup\n",
    "<a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import datasets\n",
    "import pickle\n",
    "import itertools\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import PIL.Image\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from math import sqrt\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from scipy.spatial.distance import squareform\n",
    "import pycountry\n",
    "from geonamescache import GeonamesCache\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "import textwrap\n",
    "import matplotlib.patches as mpatches\n",
    "import operator\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import imageio\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, HBox, Layout\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "from matplotlib.transforms import Bbox\n",
    "from IPython.display import clear_output\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = sns.color_palette('Set2')\n",
    "SAME_EXTENT = (-0.5, 6.5, -0.5, 6.5)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not os.path.exists(\"dataloader_files\"):\n",
    "    os.mkdir(\"dataloader_files\")\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.mkdir(\"checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/31517194/how-to-hide-one-specific-cell-input-or-output-in-ipython-notebook\n",
    "def hide_toggle(for_next=False, toggle_text='Toggle show/hide'):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True, toggle_text='Show/hide helper functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder(num, folder):\n",
    "    if not os.path.exists(\"results/{0}/{1}\".format(folder, num)):\n",
    "        os.mkdir(\"results/{0}/{1}\".format(folder, num))\n",
    "    file = open(\"results/{0}/{1}/results.txt\".format(folder, num), \"w\")\n",
    "    return file\n",
    "\n",
    "# Projecting a set of features into a lower-dimensional subspace with PCA\n",
    "def project(features, dim):\n",
    "    standardized = StandardScaler().fit_transform(features)\n",
    "    pca = PCA(n_components=dim)\n",
    "    principalComponents = pca.fit_transform(X=standardized)\n",
    "    return principalComponents\n",
    "\n",
    "# Calculating the binomial proportion confidence interval\n",
    "def wilson(p, n, z = 1.96):\n",
    "    denominator = 1 + z**2/n\n",
    "    centre_adjusted_probability = p + z*z / (2*n)\n",
    "    adjusted_standard_deviation = sqrt((p*(1 - p) + z*z / (4*n)) / n)\n",
    "    \n",
    "    lower_bound = (centre_adjusted_probability - z*adjusted_standard_deviation) / denominator\n",
    "    upper_bound = (centre_adjusted_probability + z*adjusted_standard_deviation) / denominator\n",
    "    return (lower_bound, upper_bound)\n",
    "\n",
    "def country_to_iso3(country):\n",
    "    missing = {'South+Korea': 'KOR',\n",
    "            'North+Korea': 'PRK',\n",
    "            'Laos': 'LAO',\n",
    "            'Caribbean+Netherlands': 'BES',\n",
    "            'St.+Lucia': 'LCA',\n",
    "            'East+Timor': 'TLS',\n",
    "            'Democratic+Republic+of+Congo': 'COD',\n",
    "            'Swaziland': 'SWZ',\n",
    "            'Cape+Verde': 'CPV',\n",
    "            'C%C3%B4te+d%C2%B4Ivoire': 'CIV',\n",
    "            'Ivory+Coast': 'CIV',\n",
    "            'Channel+Islands': 'GBR'\n",
    "            }\n",
    "    try:\n",
    "        iso3 = pycountry.countries.search_fuzzy(country.replace('+', ' '))[0].alpha_3\n",
    "    except LookupError:\n",
    "        try:\n",
    "            iso3 = missing[country]\n",
    "        except KeyError:\n",
    "            iso3 = None\n",
    "    return iso3\n",
    "\n",
    "def full_extent(ax, pad=0.0):\n",
    "    \"\"\"Get the full extent of an axes, including axes labels, tick labels, and\n",
    "    titles.\"\"\"\n",
    "    # For text objects, we need to draw the figure first, otherwise the extents\n",
    "    # are undefined.\n",
    "    ax.figure.canvas.draw()\n",
    "    items = ax.get_xticklabels() + ax.get_yticklabels() \n",
    "    items += [ax, ax.title]\n",
    "    bbox = Bbox.union([item.get_window_extent() for item in items])\n",
    "\n",
    "    return bbox.expanded(1.0 + pad, 1.0 + pad)\n",
    "\n",
    "def display_filepaths(filepaths, width=100, height=100):\n",
    "    sidebyside = widgets.HBox([widgets.Image(value=open(filepath, 'rb').read(), format='png', width=width, height=height) for filepath in filepaths], layout=Layout(height='{}px'.format(height)))\n",
    "    display(sidebyside)\n",
    "\n",
    "def dec_to_show(p):\n",
    "    if p < .001:\n",
    "        return '{:0.3e}'.format(p)\n",
    "    else:\n",
    "        return round(p, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Fill in below with dataset and file path names\n",
    "<a id=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([ \n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "dataset = datasets.CoCoDataset(transform_train)\n",
    "folder_name = 'coco_example'\n",
    "\n",
    "# dataset = datasets.OpenImagesDataset(transform_train)\n",
    "# folder_name = 'openimages_supp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loc = '1_pager_gen'\n",
    "os.system(\"rm -r results/{0}/{1}\".format(folder_name, save_loc))\n",
    "file = folder(save_loc, folder_name)\n",
    "first_pass = True\n",
    "to_write = {}\n",
    "if not os.path.exists(\"checkpoints/{}\".format(folder_name)):\n",
    "    os.mkdir(\"checkpoints/{}\".format(folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = None\n",
    "\n",
    "distances = pickle.load(open(\"results/{}/3.pkl\".format(folder_name), \"rb\"))\n",
    "sample_file = distances[0][0][0][3]\n",
    "if not os.path.exists(sample_file):\n",
    "    assert data_folder is not None, \"initialize data_folder with folder path of your data\"\n",
    "    dataset.init_folder_path(data_folder)\n",
    "    print(\"overwriting from_path() function\")\n",
    "    dataset.from_path = dataset.from_path_prerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = dataset.attribute_names\n",
    "num_attrs = len(attr_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (M1) Metric: Distance from center, size, attribute label inference\n",
    "<a id=\"metric1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "<a id=\"metric1_setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True, toggle_text='Show/hide M1 code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pickle.load(open(\"results/{}/1.pkl\".format(folder_name), \"rb\"))\n",
    "sizes = info['sizes']\n",
    "dists = info['distances']\n",
    "tiny_sizes = info['tiny_sizes']\n",
    "no_faces = info['noface_sizes']\n",
    "        \n",
    "scenes = [None]*num_attrs\n",
    "for attr in range(num_attrs):\n",
    "    try:\n",
    "        scenes[attr]=np.array(list(itertools.chain.from_iterable([chunk[2] for chunk in no_faces[attr]])) + list(itertools.chain.from_iterable([chunk[1] for chunk in tiny_sizes[attr]])))\n",
    "    except TypeError:\n",
    "        if len(tiny_sizes)==0:\n",
    "            print(\"There are no images with faces too small to label for group: {0}\".format(attr_names[attr]))\n",
    "        else:\n",
    "            print(\"There are no images where a face is not detected for group: {0}\".format(attr_names[attr]))\n",
    "    tiny_sizes[attr] = [chunk[0] for chunk in tiny_sizes[attr]]\n",
    "    no_faces[attr] = [chunk[0] for chunk in no_faces[attr]]\n",
    "    \n",
    "info = pickle.load(open('util_files/places_scene_info.pkl', 'rb'))\n",
    "idx_to_scene = info['idx_to_scene']\n",
    "idx_to_scenegroup = info['idx_to_scenegroup']\n",
    "sceneidx_to_scenegroupidx = info['sceneidx_to_scenegroupidx']\n",
    "\n",
    "xaxis = [idx_to_scenegroup[i] for i in range(len(idx_to_scenegroup))]\n",
    "xaxis = ['\\n'.join(textwrap.wrap(chunk, width=30)) for chunk in xaxis]\n",
    "barWidth = .4\n",
    "fontsize = 15\n",
    "\n",
    "r1 = np.arange(len(idx_to_scenegroup))\n",
    "r1 = r1 * ((barWidth * num_attrs) + .2)\n",
    "\n",
    "scenes = [np.bincount(scenes[i]) for i in range(num_attrs)]\n",
    "total_images = np.sum(scenes)\n",
    "scenes_ratio = [scenes[i]/total_images for i in range(num_attrs)]\n",
    "\n",
    "all_sizes = [tiny_sizes[i]+no_faces[i]+sizes[i] for i in range(num_attrs)]\n",
    "\n",
    "def numbers_where_attribute_inferred():\n",
    "    tiny = [len(tiny_sizes[i]) for i in range(num_attrs)]\n",
    "    noface = [len(no_faces[i]) for i in range(num_attrs)]\n",
    "    original = [tiny[i]+noface[i]+len(sizes[i]) for i in range(num_attrs)]\n",
    "    \n",
    "    total_original = np.sum(original)\n",
    "    if total_original >0:\n",
    "        print(\"Total labelled images: {0},\".format(total_original))\n",
    "    for i in range(num_attrs):\n",
    "        if original[i]>0:\n",
    "            print(\"{0} were {1}\".format(original[i], attr_names[i]))\n",
    "      \n",
    "    max_original = 0\n",
    "    max_attribute = -1\n",
    "    for attr in range(num_attrs):\n",
    "        if not math.isnan(original[attr]/total_original) and original[attr]/total_original > max_original:\n",
    "            max_original = original[attr]/total_original\n",
    "            max_attribute = attr\n",
    "    if max_attribute > -1:\n",
    "        print(\"{0} is assigned to {1}% labelled images in the dataset, and is the most commonly assigned label\".format(attr_names[max_attribute], round(max_original, 4)*100))  \n",
    "    print()\n",
    "    \n",
    "    tiny_total = np.sum(tiny)\n",
    "    if tiny_total > 0:\n",
    "        print(\"Discarded {0} images for being too small,\".format(tiny_total))\n",
    "    for i in range(num_attrs):\n",
    "        if tiny[i]>0:\n",
    "            print(\"{0} were {1}\".format(tiny[i], attr_names[i]))\n",
    "        \n",
    "    max_original = 0\n",
    "    max_attribute = -1\n",
    "    for attr in range(num_attrs):\n",
    "        if not math.isnan(tiny[attr]/tiny_total) and tiny[attr]/tiny_total > max_original:\n",
    "            max_original = tiny[attr]/tiny_total\n",
    "            max_attribute = attr\n",
    "    if max_attribute > -1:\n",
    "        print(\"{0} is assigned to {1}% labelled images where a person is too small to properly see, and is the most commonly assigned label among such images\".format(attr_names[max_attribute], round(max_original, 4)*100))\n",
    "    print()\n",
    "    \n",
    "    noface_total = np.sum(noface)\n",
    "    if noface_total >0:\n",
    "        print(\"Discarded {0} images for having no face detected,\".format(noface_total))\n",
    "    for i in range(num_attrs):\n",
    "        if noface[i] >0:\n",
    "            print(\"{0} were {1}\".format(noface[i], attr_names[i]))\n",
    "        \n",
    "    max_original = 0\n",
    "    max_attribute = -1\n",
    "    for attr in range(num_attrs):\n",
    "        if not math.isnan(noface[attr]/noface_total) and noface[attr]/noface_total > max_original:\n",
    "            max_original = noface[attr]/noface_total\n",
    "            max_attribute = attr\n",
    "    if max_attribute > -1:\n",
    "        print(\"{0} is assigned to {1}% labelled images where a face is not detected, and is the most commonly assigned label among such images\".format(attr_names[max_attribute], round(max_original, 4)*100))\n",
    "       \n",
    "    labelled = [tiny[i]+noface[i] for i in range(num_attrs)]\n",
    "    max_labelled = np.argmax(labelled)\n",
    "    labelled_others = np.sum(labelled)\n",
    "    prob = labelled[max_labelled] / labelled_others\n",
    "    prob_statement = \"Probability image is labeled {0} when it should not be, i.e. given there's no face detected or person is too small: {1}\".format(attr_names[max_labelled], round(prob, 4))\n",
    "    if (prob < .45 or prob > .55) and first_pass:\n",
    "        to_write[0] = [\"(M1) \" + prob_statement]\n",
    "    print()\n",
    "    print(prob_statement)\n",
    "    \n",
    "def scenes_where_no_face():\n",
    "    barWidths = [barWidth * i for i in range(num_attrs)]\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    r = [r1]\n",
    "    for i in range(1, num_attrs+1):\n",
    "        r.append([x + barWidth for x in r[len(r)-1]])\n",
    "        \n",
    "    scene_attr_ratios = [0 for i in range(len(scenes[0]))]\n",
    "    max_scenes = [0 for i in range(len(scenes[0]))]\n",
    "    for scene in range(len(scenes[0])):\n",
    "        max_scene = 0\n",
    "        min_scene = 1\n",
    "        max_attr = -1\n",
    "        for attr in range(num_attrs):\n",
    "            if scenes_ratio[attr][scene] > max_scene:\n",
    "                max_scene = scenes_ratio[attr][scene]\n",
    "                max_attr = attr\n",
    "            if scenes_ratio[attr][scene] < min_scene:\n",
    "                min_scene = scenes_ratio[attr][scene]\n",
    "        scene_attr_ratios[scene] = max_scene / min_scene\n",
    "        max_scenes[scene] = max_attr\n",
    "            \n",
    "    order = np.argsort(scene_attr_ratios)\n",
    "    biggest_diff_scenes = []\n",
    "    if first_pass and scene_attr_ratios[order[-1]] > 1.:\n",
    "        biggest_diff_scenes.append(\"{0} is the scene where the label of {1} is most likely to be picked over that of others\".format(xaxis[order[-1]], attr_names[max_scenes[order[-1]]]))\n",
    "    if first_pass and scene_attr_ratios[order[0]] < 1.:\n",
    "        biggest_diff_scenes.append(\"{0} is the scene where the label of {1} is most likely to be picked over that of others\".format(xaxis[order[0]], attr_names[max_scenes[order[0]]]))\n",
    "    if len(biggest_diff_scenes) > 0:\n",
    "        to_write[1] = biggest_diff_scenes\n",
    "     \n",
    "    for i in range(num_attrs-1, -1, -1):\n",
    "        plt.barh(r[i], scenes_ratio[i][order], height=barWidth, color=COLORS[i], edgecolor='white', label=attr_names[i])\n",
    "    ticks = r[0]+(num_attrs/2)*barWidth\n",
    "    plt.yticks(ticks, np.array(xaxis)[order], fontsize=fontsize)\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.ylabel('Scene', fontsize=fontsize)\n",
    "    plt.xlabel('Proportion of Labelled Images Discarded with this Scene', fontsize=fontsize)\n",
    "    plt.legend(loc='best', prop={'size': fontsize})\n",
    "    plt.title(\"Scenes where image was labeled when it should not have been\", fontsize=fontsize)\n",
    "    plt.tight_layout()\n",
    "    plt.gcf().subplots_adjust(bottom=0.18)\n",
    "    plt.gcf().subplots_adjust(left=0.4)\n",
    "    plt.show()\n",
    "    \n",
    "comparisons_widget = widgets.Dropdown(options=['Sizes', 'Distances', 'All sizes', 'Sizes where no face was detected'], value='Sizes')\n",
    "\n",
    "def compare_sizedist(metric):\n",
    "    def mean_and_std(data, data_type):\n",
    "        mean = [np.mean(data[i]) for i in range(num_attrs)]\n",
    "        std = [np.std(data[i]) for i in range(num_attrs)]\n",
    "\n",
    "        min_p = 100\n",
    "        one = -1\n",
    "        two = -1\n",
    "        for i in range(num_attrs):\n",
    "            for a in range(i+1, num_attrs):\n",
    "                t, p = stats.ttest_ind(data[i], data[a])\n",
    "                if p < min_p:\n",
    "                    min_p=p\n",
    "                    one = i\n",
    "                    two = a\n",
    "        p = min_p\n",
    "\n",
    "        to_save = False\n",
    "        if metric == 'first_pass' and p < .05 and first_pass:\n",
    "            data_descrip = ''\n",
    "            if data_type == 'dists':\n",
    "                data_descrip = 'Distance from center'\n",
    "            if data_type == 'sizes':\n",
    "                data_descrip = 'Fraction of image taken up by a person'\n",
    "            to_write[2] = [\"(M1) {0} is different between the attributes with a p-value of {1} for the most significant pair ({2} and {3}), distribution shown below\".format(data_descrip, dec_to_show(p), attr_names[one], attr_names[two])]\n",
    "            to_save = True\n",
    "            \n",
    "        if metric == 'first_pass' or metric != 'first_pass':\n",
    "            for i in range(num_attrs):\n",
    "                histogram_a, bins_a = np.histogram(data[i], bins='auto')\n",
    "                bin_centers_a = 0.5*(bins_a[1:] + bins_a[:-1])\n",
    "                area_a = np.trapz(histogram_a, x=bin_centers_a)\n",
    "                plt.plot(bin_centers_a, histogram_a/area_a, alpha=.75, label=attr_names[i], color=COLORS[i])\n",
    "\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.xlabel('Distances' if data_type == 'dists' else 'Sizes')\n",
    "            plt.ylabel('Frequency')\n",
    "            if to_save and first_pass:\n",
    "                plt.savefig(\"results/{0}/{1}/0.png\".format(folder_name, save_loc))\n",
    "                plt.close()\n",
    "            elif metric == 'first_pass':\n",
    "                plt.close()\n",
    "            else:\n",
    "                plt.show()\n",
    "\n",
    "        if metric != 'first_pass':\n",
    "            for i in range(num_attrs):\n",
    "                print(\"{0}: {1} +- {2}\\n\".format(attr_names[i], round(mean[i], 4), round(std[i], 4)))\n",
    "            print(\"The smallest P value, which is between the groups {} and {}: {}\\n\".format(attr_names[one],attr_names[two], '{:0.3e}'.format(p)))\n",
    "\n",
    "    if metric == 'Sizes':\n",
    "        mean_and_std(sizes, 'sizes')\n",
    "    elif metric == 'All sizes':\n",
    "        mean_and_std(all_sizes, 'all_sizes')\n",
    "    elif metric == 'Sizes where no face was detected':\n",
    "        mean_and_std(no_faces, 'no_faces')  \n",
    "    elif metric == 'Distances':\n",
    "        mean_and_std(dists, 'dists')\n",
    "    elif metric == 'first_pass' and first_pass:\n",
    "        mean_and_std(sizes, 'sizes')\n",
    "        mean_and_std(dists, 'dists')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses \n",
    "<a id=\"metric1_analyses\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics on how many attribute labels were inferred when they shouldn't have been because the person was either too small, or no face was detected. The scenes where this happens are shown to investigate if perhaps annotators are relying on contextual clues to make this assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numbers_where_attribute_inferred()\n",
    "scenes_where_no_face()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution by attribute of sizes and distances, both after removing images where attribute was unlikely to be able to be labeled, all sizes before any images were removed, and the sizes of people where no face was detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_pass:\n",
    "    compare_sizedist('first_pass')\n",
    "all_things = [comparisons_widget]\n",
    "ui = HBox(all_things)\n",
    "out = widgets.interactive_output(compare_sizedist, {'metric': comparisons_widget})\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
