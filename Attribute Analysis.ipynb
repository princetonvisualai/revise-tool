{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute Analysis\n",
    "The following notebook can analyze a given attribute with any number of expected values (2+), and will perform metrics att_siz, att_cnt, att_dis, att_clu, att_scn generalized to any attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruction\n",
    "1. Fill in the dataset in section 1.1\n",
    "\n",
    "2. Run all cells\n",
    "\n",
    "3. Look at the summary pdf generated AND/OR explore each metric below.\n",
    "    - All metrics are identified by a short keyword, and consist of a \"Setup\" and \"Analyses\" portion. The \"Setup\" portion contains code that does not need to be modified unless customization is needed, and the \"Analyses\" portion provides an interactive display of the results.\n",
    "    \n",
    "## Table of Contents\n",
    "1. [Initial Setup](#setup) <br/>\n",
    "    1.1 [Dataset](#dataset) <br/>\n",
    "2. att_siz Metric: [Distance from center, size, attribute label inference](#att_size)<br/>\n",
    "    2.1 [Setup](#att_size_setup)<br/>\n",
    "    2.2 [Analyses](#att_size_analyses)\n",
    "3. att_cnt Metric: [Object occurrences and cooccurrences](#att_cnt)<br/>\n",
    "    3.1 [Setup](#att_cnt_setup)<br/>\n",
    "    3.2 [Analyses](#att_cnt_analyses)\n",
    "4. att_clu Metric: [Linearly seperate objects by attribute](#att_clu)<br/>\n",
    "    4.1 [Setup](#att_clu_setup)<br/>\n",
    "    4.2 [Analyses](#att_clu_analyses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup\n",
    "<a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import argparse\n",
    "import datasets\n",
    "import pickle\n",
    "import itertools\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import PIL.Image\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from math import sqrt\n",
    "import cv2\n",
    "import matplotlib.patches as patches\n",
    "from scipy.spatial.distance import squareform\n",
    "import pycountry\n",
    "from geonamescache import GeonamesCache\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "import textwrap\n",
    "import matplotlib.patches as mpatches\n",
    "import operator\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import imageio\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, HBox, Layout\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "from matplotlib.transforms import Bbox\n",
    "from IPython.display import clear_output\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = sns.color_palette('Set2')\n",
    "SAME_EXTENT = (-0.5, 6.5, -0.5, 6.5)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not os.path.exists(\"dataloader_files\"):\n",
    "    os.mkdir(\"dataloader_files\")\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.mkdir(\"checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/31517194/how-to-hide-one-specific-cell-input-or-output-in-ipython-notebook\n",
    "def hide_toggle(for_next=False, toggle_text='Toggle show/hide'):\n",
    "    this_cell = \"\"\"$('div.cell.code_cell.rendered.selected')\"\"\"\n",
    "    next_cell = this_cell + '.next()'\n",
    "\n",
    "    target_cell = this_cell  # target cell to control with toggle\n",
    "    js_hide_current = ''  # bit of JS to permanently hide code in current cell (only when toggling next cell)\n",
    "\n",
    "    if for_next:\n",
    "        target_cell = next_cell\n",
    "        js_hide_current = this_cell + '.find(\"div.input\").hide();'\n",
    "\n",
    "    js_f_name = 'code_toggle_{}'.format(str(random.randint(1,2**64)))\n",
    "\n",
    "    html = \"\"\"\n",
    "        <script>\n",
    "            function {f_name}() {{\n",
    "                {cell_selector}.find('div.input').toggle();\n",
    "            }}\n",
    "\n",
    "            {js_hide_current}\n",
    "        </script>\n",
    "\n",
    "        <a href=\"javascript:{f_name}()\">{toggle_text}</a>\n",
    "    \"\"\".format(\n",
    "        f_name=js_f_name,\n",
    "        cell_selector=target_cell,\n",
    "        js_hide_current=js_hide_current, \n",
    "        toggle_text=toggle_text\n",
    "    )\n",
    "\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True, toggle_text='Show/hide helper functions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder(num, folder):\n",
    "    if not os.path.exists(\"results/{0}/{1}\".format(folder, num)):\n",
    "        os.mkdir(\"results/{0}/{1}\".format(folder, num))\n",
    "    file = open(\"results/{0}/{1}/results.txt\".format(folder, num), \"w\")\n",
    "    return file\n",
    "\n",
    "# Projecting a set of features into a lower-dimensional subspace with PCA\n",
    "def project(features, dim):\n",
    "    standardized = StandardScaler().fit_transform(features)\n",
    "    pca = PCA(n_components=dim)\n",
    "    principalComponents = pca.fit_transform(X=standardized)\n",
    "    return principalComponents\n",
    "\n",
    "# Calculating the binomial proportion confidence interval\n",
    "def wilson(p, n, z = 1.96):\n",
    "    denominator = 1 + z**2/n\n",
    "    centre_adjusted_probability = p + z*z / (2*n)\n",
    "    adjusted_standard_deviation = sqrt((p*(1 - p) + z*z / (4*n)) / n)\n",
    "    \n",
    "    lower_bound = (centre_adjusted_probability - z*adjusted_standard_deviation) / denominator\n",
    "    upper_bound = (centre_adjusted_probability + z*adjusted_standard_deviation) / denominator\n",
    "    return (lower_bound, upper_bound)\n",
    "\n",
    "def country_to_iso3(country):\n",
    "    missing = {'South+Korea': 'KOR',\n",
    "            'North+Korea': 'PRK',\n",
    "            'Laos': 'LAO',\n",
    "            'Caribbean+Netherlands': 'BES',\n",
    "            'St.+Lucia': 'LCA',\n",
    "            'East+Timor': 'TLS',\n",
    "            'Democratic+Republic+of+Congo': 'COD',\n",
    "            'Swaziland': 'SWZ',\n",
    "            'Cape+Verde': 'CPV',\n",
    "            'C%C3%B4te+d%C2%B4Ivoire': 'CIV',\n",
    "            'Ivory+Coast': 'CIV',\n",
    "            'Channel+Islands': 'GBR'\n",
    "            }\n",
    "    try:\n",
    "        iso3 = pycountry.countries.search_fuzzy(country.replace('+', ' '))[0].alpha_3\n",
    "    except LookupError:\n",
    "        try:\n",
    "            iso3 = missing[country]\n",
    "        except KeyError:\n",
    "            iso3 = None\n",
    "    return iso3\n",
    "\n",
    "def full_extent(ax, pad=0.0):\n",
    "    \"\"\"Get the full extent of an axes, including axes labels, tick labels, and\n",
    "    titles.\"\"\"\n",
    "    # For text objects, we need to draw the figure first, otherwise the extents\n",
    "    # are undefined.\n",
    "    ax.figure.canvas.draw()\n",
    "    items = ax.get_xticklabels() + ax.get_yticklabels() \n",
    "    items += [ax, ax.title]\n",
    "    bbox = Bbox.union([item.get_window_extent() for item in items])\n",
    "\n",
    "    return bbox.expanded(1.0 + pad, 1.0 + pad)\n",
    "\n",
    "def display_filepaths(filepaths, width=100, height=100):\n",
    "    try: \n",
    "        sidebyside = widgets.HBox([widgets.Image(value=open(filepath, 'rb').read(), format='png', width=width, height=height) for filepath in filepaths], layout=Layout(height='{}px'.format(height)))\n",
    "        display(sidebyside)\n",
    "    except FileNotFoundError: \n",
    "        print('Filepath not found. If using CocoDatasetNoImages Class, some functionality is not available.')\n",
    "\n",
    "def dec_to_show(p):\n",
    "    if p < .001:\n",
    "        return '{:0.3e}'.format(p)\n",
    "    else:\n",
    "        return round(p, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Fill in below with dataset and file path names\n",
    "<a id=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([ \n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "dataset = datasets.CoCoDataset(transform_train)\n",
    "folder_name = 'coco_example'\n",
    "\n",
    "# dataset = datasets.OpenImagesDataset(transform_train)\n",
    "# folder_name = 'openimages_supp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loc = '1_pager_gen'\n",
    "os.system(\"rm -r results/{0}/{1}\".format(folder_name, save_loc))\n",
    "file = folder(save_loc, folder_name)\n",
    "first_pass = True\n",
    "to_write = {}\n",
    "if not os.path.exists(\"checkpoints/{}\".format(folder_name)):\n",
    "    os.mkdir(\"checkpoints/{}\".format(folder_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = None\n",
    "\n",
    "distances = pickle.load(open(\"results/{}/att_dis.pkl\".format(folder_name), \"rb\"))\n",
    "sample_file = distances[0][0][0][3]\n",
    "if not os.path.exists(sample_file):\n",
    "    assert data_folder is not None, \"initialize data_folder with folder path of your data\"\n",
    "    dataset.init_folder_path(data_folder)\n",
    "    print(\"overwriting from_path() function\")\n",
    "    dataset.from_path = dataset.from_path_prerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = dataset.attribute_names\n",
    "num_attrs = len(attr_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# att_siz Metric: Distance from center, size, attribute label inference\n",
    "<a id=\"att_siz\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "<a id=\"att_siz_setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True, toggle_text='Show/hide att_siz code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pickle.load(open(\"results/{}/att_siz.pkl\".format(folder_name), \"rb\"))\n",
    "sizes = info['sizes']\n",
    "dists = info['distances']\n",
    "tiny_sizes = info['tiny_sizes']\n",
    "no_faces = info['noface_sizes']\n",
    "        \n",
    "scenes = [None]*num_attrs\n",
    "for attr in range(num_attrs):\n",
    "    try:\n",
    "        scenes[attr]=np.array(list(itertools.chain.from_iterable([chunk[2] for chunk in no_faces[attr]])) + list(itertools.chain.from_iterable([chunk[1] for chunk in tiny_sizes[attr]])))\n",
    "    except TypeError:\n",
    "        if len(tiny_sizes)==0:\n",
    "            print(\"There are no images with faces too small to label for group: {0}\".format(attr_names[attr]))\n",
    "        else:\n",
    "            print(\"There are no images where a face is not detected for group: {0}\".format(attr_names[attr]))\n",
    "    tiny_sizes[attr] = [chunk[0] for chunk in tiny_sizes[attr]]\n",
    "    no_faces[attr] = [chunk[0] for chunk in no_faces[attr]]\n",
    "    \n",
    "info = pickle.load(open('util_files/places_scene_info.pkl', 'rb'))\n",
    "idx_to_scene = info['idx_to_scene']\n",
    "idx_to_scenegroup = info['idx_to_scenegroup']\n",
    "sceneidx_to_scenegroupidx = info['sceneidx_to_scenegroupidx']\n",
    "\n",
    "xaxis = [idx_to_scenegroup[i] for i in range(len(idx_to_scenegroup))]\n",
    "xaxis = ['\\n'.join(textwrap.wrap(chunk, width=30)) for chunk in xaxis]\n",
    "barWidth = .4\n",
    "fontsize = 15\n",
    "\n",
    "r1 = np.arange(len(idx_to_scenegroup))\n",
    "r1 = r1 * ((barWidth * num_attrs) + .2)\n",
    "\n",
    "scenes = [np.bincount(scenes[i]) for i in range(num_attrs)]\n",
    "total_images = np.sum(scenes)\n",
    "scenes_ratio = [scenes[i]/total_images for i in range(num_attrs)]\n",
    "\n",
    "all_sizes = [tiny_sizes[i]+no_faces[i]+sizes[i] for i in range(num_attrs)]\n",
    "\n",
    "def numbers_where_attribute_inferred():\n",
    "    tiny = [len(tiny_sizes[i]) for i in range(num_attrs)]\n",
    "    noface = [len(no_faces[i]) for i in range(num_attrs)]\n",
    "    original = [tiny[i]+noface[i]+len(sizes[i]) for i in range(num_attrs)]\n",
    "    \n",
    "    total_original = np.sum(original)\n",
    "    if total_original >0:\n",
    "        print(\"Total labelled images: {0},\".format(total_original))\n",
    "    for i in range(num_attrs):\n",
    "        if original[i]>0:\n",
    "            print(\"{0} were {1}\".format(original[i], attr_names[i]))\n",
    "      \n",
    "    max_original = 0\n",
    "    max_attribute = -1\n",
    "    for attr in range(num_attrs):\n",
    "        if not math.isnan(original[attr]/total_original) and original[attr]/total_original > max_original:\n",
    "            max_original = original[attr]/total_original\n",
    "            max_attribute = attr\n",
    "    if max_attribute > -1:\n",
    "        print(\"{0} is assigned to {1}% labelled images in the dataset, and is the most commonly assigned label\".format(attr_names[max_attribute], round(max_original, 4)*100))  \n",
    "    print()\n",
    "    \n",
    "    tiny_total = np.sum(tiny)\n",
    "    if tiny_total > 0:\n",
    "        print(\"Discarded {0} images for being too small,\".format(tiny_total))\n",
    "    for i in range(num_attrs):\n",
    "        if tiny[i]>0:\n",
    "            print(\"{0} were {1}\".format(tiny[i], attr_names[i]))\n",
    "        \n",
    "    max_original = 0\n",
    "    max_attribute = -1\n",
    "    for attr in range(num_attrs):\n",
    "        if not math.isnan(tiny[attr]/tiny_total) and tiny[attr]/tiny_total > max_original:\n",
    "            max_original = tiny[attr]/tiny_total\n",
    "            max_attribute = attr\n",
    "    if max_attribute > -1:\n",
    "        print(\"{0} is assigned to {1}% labelled images where a person is too small to properly see, and is the most commonly assigned label among such images\".format(attr_names[max_attribute], round(max_original, 4)*100))\n",
    "    print()\n",
    "    \n",
    "    noface_total = np.sum(noface)\n",
    "    if noface_total >0:\n",
    "        print(\"Discarded {0} images for having no face detected,\".format(noface_total))\n",
    "    for i in range(num_attrs):\n",
    "        if noface[i] >0:\n",
    "            print(\"{0} were {1}\".format(noface[i], attr_names[i]))\n",
    "        \n",
    "    max_original = 0\n",
    "    max_attribute = -1\n",
    "    for attr in range(num_attrs):\n",
    "        if not math.isnan(noface[attr]/noface_total) and noface[attr]/noface_total > max_original:\n",
    "            max_original = noface[attr]/noface_total\n",
    "            max_attribute = attr\n",
    "    if max_attribute > -1:\n",
    "        print(\"{0} is assigned to {1}% labelled images where a face is not detected, and is the most commonly assigned label among such images\".format(attr_names[max_attribute], round(max_original, 4)*100))\n",
    "       \n",
    "    labelled = [tiny[i]+noface[i] for i in range(num_attrs)]\n",
    "    max_labelled = np.argmax(labelled)\n",
    "    labelled_others = np.sum(labelled)\n",
    "    prob = labelled[max_labelled] / labelled_others\n",
    "    prob_statement = \"Probability image is labeled {0} when it should not be, i.e. given there's no face detected or person is too small: {1}\".format(attr_names[max_labelled], round(prob, 4))\n",
    "    if (prob < .45 or prob > .55) and first_pass:\n",
    "        to_write[0] = [\"(att_siz) \" + prob_statement]\n",
    "    print()\n",
    "    print(prob_statement)\n",
    "    \n",
    "def scenes_where_no_face():\n",
    "    barWidths = [barWidth * i for i in range(num_attrs)]\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    r = [r1]\n",
    "    for i in range(1, num_attrs+1):\n",
    "        r.append([x + barWidth for x in r[len(r)-1]])\n",
    "        \n",
    "    scene_attr_ratios = [0 for i in range(len(scenes[0]))]\n",
    "    max_scenes = [0 for i in range(len(scenes[0]))]\n",
    "    for scene in range(len(scenes[0])):\n",
    "        max_scene = 0\n",
    "        min_scene = 1\n",
    "        max_attr = -1\n",
    "        for attr in range(num_attrs):\n",
    "            if scenes_ratio[attr][scene] > max_scene:\n",
    "                max_scene = scenes_ratio[attr][scene]\n",
    "                max_attr = attr\n",
    "            if scenes_ratio[attr][scene] < min_scene:\n",
    "                min_scene = scenes_ratio[attr][scene]\n",
    "        scene_attr_ratios[scene] = max_scene / min_scene\n",
    "        max_scenes[scene] = max_attr\n",
    "            \n",
    "    order = np.argsort(scene_attr_ratios)\n",
    "    biggest_diff_scenes = []\n",
    "    if first_pass and scene_attr_ratios[order[-1]] > 1.:\n",
    "        biggest_diff_scenes.append(\"{0} is the scene where the label of {1} is most likely to be picked over that of others\".format(xaxis[order[-1]], attr_names[max_scenes[order[-1]]]))\n",
    "    if first_pass and scene_attr_ratios[order[0]] < 1.:\n",
    "        biggest_diff_scenes.append(\"{0} is the scene where the label of {1} is most likely to be picked over that of others\".format(xaxis[order[0]], attr_names[max_scenes[order[0]]]))\n",
    "    if len(biggest_diff_scenes) > 0:\n",
    "        to_write[1] = biggest_diff_scenes\n",
    "     \n",
    "    for i in range(num_attrs-1, -1, -1):\n",
    "        plt.barh(r[i], scenes_ratio[i][order], height=barWidth, color=COLORS[i], edgecolor='white', label=attr_names[i])\n",
    "    ticks = r[0]+(num_attrs/2)*barWidth\n",
    "    plt.yticks(ticks, np.array(xaxis)[order], fontsize=fontsize)\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.ylabel('Scene', fontsize=fontsize)\n",
    "    plt.xlabel('Proportion of Labelled Images Discarded with this Scene', fontsize=fontsize)\n",
    "    plt.legend(loc='best', prop={'size': fontsize})\n",
    "    plt.title(\"Scenes where image was labeled when it should not have been\", fontsize=fontsize)\n",
    "    plt.tight_layout()\n",
    "    plt.gcf().subplots_adjust(bottom=0.18)\n",
    "    plt.gcf().subplots_adjust(left=0.4)\n",
    "    plt.show()\n",
    "    \n",
    "comparisons_widget = widgets.Dropdown(options=['Sizes', 'Distances', 'All sizes', 'Sizes where no face was detected'], value='Sizes')\n",
    "\n",
    "def compare_sizedist(metric):\n",
    "    def mean_and_std(data, data_type):\n",
    "        mean = [np.mean(data[i]) for i in range(num_attrs)]\n",
    "        std = [np.std(data[i]) for i in range(num_attrs)]\n",
    "\n",
    "        min_p = 100\n",
    "        one = -1\n",
    "        two = -1\n",
    "        for i in range(num_attrs):\n",
    "            for a in range(i+1, num_attrs):\n",
    "                t, p = stats.ttest_ind(data[i], data[a])\n",
    "                if p < min_p:\n",
    "                    min_p=p\n",
    "                    one = i\n",
    "                    two = a\n",
    "        p = min_p\n",
    "\n",
    "        to_save = False\n",
    "        if metric == 'first_pass' and p < .05 and first_pass:\n",
    "            data_descrip = ''\n",
    "            if data_type == 'dists':\n",
    "                data_descrip = 'Distance from center'\n",
    "            if data_type == 'sizes':\n",
    "                data_descrip = 'Fraction of image taken up by a person'\n",
    "            to_write[2] = [\"(att_siz) {0} is different between the attributes with a p-value of {1} for the most significant pair ({2} and {3}), distribution shown below\".format(data_descrip, dec_to_show(p), attr_names[one], attr_names[two])]\n",
    "            to_save = True\n",
    "            \n",
    "        if metric == 'first_pass' or metric != 'first_pass':\n",
    "            for i in range(num_attrs):\n",
    "                histogram_a, bins_a = np.histogram(data[i], bins='auto')\n",
    "                bin_centers_a = 0.5*(bins_a[1:] + bins_a[:-1])\n",
    "                area_a = np.trapz(histogram_a, x=bin_centers_a)\n",
    "                plt.plot(bin_centers_a, histogram_a/area_a, alpha=.75, label=attr_names[i], color=COLORS[i])\n",
    "\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.xlabel('Distances' if data_type == 'dists' else 'Sizes')\n",
    "            plt.ylabel('Frequency')\n",
    "            if to_save and first_pass:\n",
    "                plt.savefig(\"results/{0}/{1}/0.png\".format(folder_name, save_loc))\n",
    "                plt.close()\n",
    "            elif metric == 'first_pass':\n",
    "                plt.close()\n",
    "            else:\n",
    "                plt.show()\n",
    "\n",
    "        if metric != 'first_pass':\n",
    "            for i in range(num_attrs):\n",
    "                print(\"{0}: {1} +- {2}\\n\".format(attr_names[i], round(mean[i], 4), round(std[i], 4)))\n",
    "            print(\"The smallest P value, which is between the groups {} and {}: {}\\n\".format(attr_names[one],attr_names[two], '{:0.3e}'.format(p)))\n",
    "\n",
    "    if metric == 'Sizes':\n",
    "        mean_and_std(sizes, 'sizes')\n",
    "    elif metric == 'All sizes':\n",
    "        mean_and_std(all_sizes, 'all_sizes')\n",
    "    elif metric == 'Sizes where no face was detected':\n",
    "        mean_and_std(no_faces, 'no_faces')  \n",
    "    elif metric == 'Distances':\n",
    "        mean_and_std(dists, 'dists')\n",
    "    elif metric == 'first_pass' and first_pass:\n",
    "        mean_and_std(sizes, 'sizes')\n",
    "        mean_and_std(dists, 'dists')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses \n",
    "<a id=\"att_siz_analyses\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics on how many attribute labels were inferred when they shouldn't have been because the person was either too small, or no face was detected. The scenes where this happens are shown to investigate if perhaps annotators are relying on contextual clues to make this assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numbers_where_attribute_inferred()\n",
    "scenes_where_no_face()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution by attribute of sizes and distances, both after removing images where attribute was unlikely to be able to be labeled, all sizes before any images were removed, and the sizes of people where no face was detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_pass:\n",
    "    compare_sizedist('first_pass')\n",
    "all_things = [comparisons_widget]\n",
    "ui = HBox(all_things)\n",
    "out = widgets.interactive_output(compare_sizedist, {'metric': comparisons_widget})\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# att_cnt Metric: Object occurrences and cooccurrences\n",
    "<a id=\"att_cnt\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "<a id=\"att_cnt_setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True, toggle_text='Show/hide att_cnt code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = dataset.categories\n",
    "names = dataset.labels_to_names\n",
    "counts = pickle.load(open(\"results/{}/att_cnt.pkl\".format(folder_name), \"rb\"))\n",
    "topn = 10\n",
    "counts_mat = [np.zeros((len(categories), len(categories))) for i in range(num_attrs)]\n",
    "for key in counts[0].keys():\n",
    "    a, b = key.split('-')\n",
    "    a, b = int(a), int(b)\n",
    "    for attr in range(num_attrs):\n",
    "        counts_mat[attr][b][a] = counts[attr][key]\n",
    "        counts_mat[attr][a][b] = counts[attr][key]\n",
    "instance_counts = [np.diagonal(counts_mat[i]) for i in range(num_attrs)]\n",
    "normalized = [np.divide(counts_mat[i], instance_counts[i]) for i in range(num_attrs)]\n",
    "            \n",
    "def make_dist(counts, total):\n",
    "    samples = np.zeros(total)\n",
    "    samples[:int(counts)] = 1\n",
    "    return samples\n",
    "\n",
    "norm_instance_counts = [instance_counts[i]/ dataset.num_skin_tone_images[i] for i in range(num_attrs)]\n",
    "xaxis = [names[i] for i in categories]\n",
    "barWidth = .4\n",
    "\n",
    "# Looking at if the number of times an object appears with different attributes is statistically significant for all pairs of attributes\n",
    "p_values = []\n",
    "attribute_mapping = {}\n",
    "for i in range(len(instance_counts[0])):\n",
    "    for a in range(num_attrs):\n",
    "        for b in range(a+1, num_attrs):\n",
    "            p_values.append(stats.ttest_ind(make_dist(instance_counts[b][i], dataset.num_skin_tone_images[b]), make_dist(instance_counts[a][i], dataset.num_skin_tone_images[a]))[1])\n",
    "            attribute_mapping[p_values[-1]] = [a, b, xaxis[i]]\n",
    "\n",
    "# Graphs the counts of each supercategory by attribute\n",
    "def supercategory_by_attribute():\n",
    "    if dataset.group_mapping is not None:\n",
    "        fontsize = 15\n",
    "        supercategory_counts = [np.zeros(len(datasets.DEFAULT_GROUPINGS_TO_NAMES)) for i in range(num_attrs)]\n",
    "        for i in range(len(categories)):\n",
    "            supercat = dataset.group_mapping(categories[i])\n",
    "            for a in range(num_attrs):\n",
    "                supercategory_counts[a][supercat] += norm_instance_counts[a][i]\n",
    "        for a in range(num_attrs):\n",
    "            supercategory_counts[a] = supercategory_counts[a][1:]\n",
    "        supercategory_counts = [np.array(supercategory_counts[i]) for i in range(num_attrs)]\n",
    "        \n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        r1 = np.arange(len(datasets.DEFAULT_GROUPINGS_TO_NAMES)-1)\n",
    "        r1 = [r1[i]+i*4*barWidth for i in range(len(r1))]\n",
    "        r = [r1]\n",
    "        for i in range(1, num_attrs+1):\n",
    "            r.append([x + barWidth for x in r[len(r)-1]])\n",
    "\n",
    "        category_attr_ratios = [0 for i in range(len(supercategory_counts[0]))]\n",
    "        max_categories = [0 for i in range(len(supercategory_counts[0]))]\n",
    "        for category in range(len(supercategory_counts[0])):\n",
    "            max_category = 0\n",
    "            min_category = 1\n",
    "            max_attr = -1\n",
    "            for attr in range(num_attrs):\n",
    "                if supercategory_counts[attr][category] > max_category:\n",
    "                    max_category = supercategory_counts[attr][category]\n",
    "                    max_attr = attr\n",
    "                if supercategory_counts[attr][category] < min_category:\n",
    "                    min_category = supercategory_counts[attr][category]\n",
    "            category_attr_ratios[category] = max_category / min_category\n",
    "            max_categories[category] = max_attr\n",
    "            \n",
    "        order = np.argsort(category_attr_ratios)\n",
    "        r = np.array(r)\n",
    "        for i in range(num_attrs-1, -1, -1):\n",
    "            plt.barh(r[i], supercategory_counts[i][order], height=barWidth, color=COLORS[i], edgecolor='white', label=attr_names[i])\n",
    "        \n",
    "        ticks = [r[0]+(num_attrs/2)*barWidth for i in range(len(r1))][0]\n",
    "        plt.yticks(ticks, np.array([datasets.DEFAULT_GROUPINGS_TO_NAMES[i+1] for i in range(len(r1))])[order], fontsize=fontsize)\n",
    "        plt.xticks(fontsize=fontsize)\n",
    "        plt.legend(loc='best', fontsize=fontsize)\n",
    "        plt.ylabel('Object Category', fontsize=fontsize, labelpad=20)\n",
    "        plt.xlabel('Fraction of Labelled Images that contain this Category', fontsize=fontsize, labelpad=20, x=.3)\n",
    "        plt.tight_layout()\n",
    "        plt.gcf().subplots_adjust(bottom=0.18)\n",
    "        plt.gcf().subplots_adjust(left=0.28)\n",
    "        if first_pass:\n",
    "            to_write[3] = ['(att_cnt) Distribution of object categories each attribute appears with, sorted by ratio between the max count attribute and min count attribute.']\n",
    "            plt.savefig(\"results/{0}/{1}/1.png\".format(folder_name, save_loc))\n",
    "        plt.show()\n",
    "\n",
    "# Graphs the ratio of instance counts if they are statistically significant\n",
    "indices_to_keep = [i for i in range(len(instance_counts[0])) if categories[i] not in dataset.people_labels]\n",
    "pspecific_indices = []\n",
    "values_forobject = int((num_attrs)*(num_attrs-1)/2)\n",
    "        \n",
    "for ind in indices_to_keep:\n",
    "    for i in range(ind*(values_forobject),ind*(values_forobject)+(values_forobject)):\n",
    "        pspecific_indices.append(i)\n",
    "\n",
    "instance_sig = [norm_instance_counts[i][indices_to_keep] for i in range(num_attrs)]\n",
    "xaxis_sig = np.array(xaxis)[indices_to_keep]\n",
    "pvalues_sig = np.array(p_values)[pspecific_indices]\n",
    "count_attr_ratio = [0 for i in range(len(instance_sig[0]))]\n",
    "max_counts = [0 for i in range(len(instance_sig[0]))]\n",
    "for i in range(len(instance_sig[0])):\n",
    "    max_count = 0\n",
    "    min_count = 0\n",
    "    max_attr = -1\n",
    "    sum_cat = 0\n",
    "    for attr in range(num_attrs):\n",
    "        sum_cat += instance_sig[attr][i]\n",
    "        if instance_sig[attr][i] > max_count:\n",
    "            max_count = instance_sig[attr][i]\n",
    "            max_attr = attr\n",
    "    if sum_cat >0:\n",
    "        count_attr_ratio[i] = float(max_count) / float(sum_cat)\n",
    "    else:\n",
    "        count_attr_ratio[i] = 0\n",
    "    max_counts[i] = max_attr\n",
    "all_ratios = np.array(count_attr_ratio)\n",
    "max_counts = np.array(max_counts)\n",
    "\n",
    "def show_instance_ratios(sort_by, topn):\n",
    "    infinities = np.concatenate([np.where(all_ratios == -np.inf)[0], np.where(all_ratios == np.inf)[0]], axis=None)\n",
    "    infinite_categories = max_counts[infinities]\n",
    "    \n",
    "    all_ratios[all_ratios == -np.inf] = 0\n",
    "    all_ratios[all_ratios == np.inf] = 0\n",
    "    \n",
    "    to_save = False\n",
    "    if topn is None:\n",
    "        topn = 5\n",
    "        to_save = True\n",
    "    \n",
    "    if sort_by == 'pvalue':\n",
    "        top_indices = np.argsort(pvalues_sig)[:topn][::-1]\n",
    "        if to_save:\n",
    "            for i in reversed(range(topn)):\n",
    "                if pvalues_sig[top_indices[i]] >= .05:\n",
    "                    top_indices.pop()\n",
    "            topn = len(top_indices)\n",
    "            if len(top_indices) == 0:\n",
    "                return\n",
    "                to_save = False\n",
    "                \n",
    "        instance_sig_topn = []\n",
    "        xaxis_sig_topn = []\n",
    "        all_ratios_topn = []\n",
    "        max_c = []\n",
    "        for pval in pvalues_sig[top_indices]:\n",
    "            info = attribute_mapping[pval]\n",
    "            index = np.where(xaxis_sig==info[2])\n",
    "            if instance_sig[info[0]][index][0]*dataset.num_skin_tone_images[info[0]] > instance_sig[info[1]][index][0]*dataset.num_skin_tone_images[info[1]]:\n",
    "                instance_sig_topn.append(instance_sig[info[0]][index][0])\n",
    "            else:\n",
    "                instance_sig_topn.append(instance_sig[info[1]][index][0])\n",
    "            xaxis_sig_topn.append(info[2])\n",
    "            all_ratios_topn.append(all_ratios[index][0])\n",
    "            max_c.append(max_counts[index][0])\n",
    "                \n",
    "    elif sort_by == 'ratio':\n",
    "        top_indices = np.argsort(np.absolute(all_ratios))[-topn:]\n",
    "        instance_sig_topn = [instance_sig[i][top_indices] for i in range(num_attrs)]\n",
    "        xaxis_sig_topn = xaxis_sig[top_indices]\n",
    "        all_ratios_topn = all_ratios[top_indices]\n",
    "        max_c = max_counts[top_indices]\n",
    "\n",
    "    fig = plt.figure(figsize=(10, max(2, topn // 3)))\n",
    "    fontsize = 10\n",
    "    pltbar = plt.barh(np.arange(topn), np.absolute(all_ratios_topn))\n",
    "    for bar in range(len(pltbar)):\n",
    "        pltbar[bar].set_color(COLORS[max_c[bar]])\n",
    "        \n",
    "    plt.yticks(np.arange(topn), xaxis_sig_topn[:topn], rotation='horizontal', fontsize=fontsize)\n",
    "    ax = plt.gca()\n",
    "    ax.tick_params(axis=\"x\", bottom=True, top=True, labelbottom=True, labeltop=True)\n",
    "    ax.tick_params(axis=\"y\", left=False, right=True, labelleft=False, labelright=True)\n",
    "    plt.ylabel('Categories', fontsize=fontsize)\n",
    "    plt.xlabel('Counts Ratio', fontsize=fontsize)\n",
    "    patches = [mpatches.Patch(color=COLORS[i], label=attr_names[i]) for i in range(num_attrs)]\n",
    "    handles = patches\n",
    "    fontP = FontProperties()\n",
    "    fontP.set_size(12)\n",
    "    lgd = plt.legend(handles=handles, prop=fontP, loc='best')\n",
    "    plt.tight_layout()\n",
    "    if to_save:\n",
    "        to_write[4] = ['(att_cnt) Objects that are most statistically significantly represented with one attribute over the other.']\n",
    "        plt.savefig(\"results/{0}/{1}/2.png\".format(folder_name, save_loc))\n",
    "        plt.close()\n",
    "        return\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    if len(infinities) > 0:\n",
    "        print(\"Categories where one attribute had 0 occurrences with that object:\\n\")\n",
    "        \n",
    "    # Categories where all attributes had 0 occurrences with that object\n",
    "    for index in infinities:\n",
    "        print(\"{0} had 0 occurrences with all values of the attribute\".format(xaxis_sig_topn[index]))\n",
    "\n",
    "    print(\"The most common attribute associated each category in the graph is:\\n\")\n",
    "    for index in reversed(range(topn)):\n",
    "        attr = int(max_c[index])\n",
    "        if sort_by == 'pvalue':\n",
    "            instance_sig_top = instance_sig_topn[index]\n",
    "        elif sort_by == 'ratio':\n",
    "            instance_sig_top = instance_sig_topn[attr][index]\n",
    "        print(\"{0}: {1}={2}, proportion of total instances: {3}\\n\".format(xaxis_sig_topn[index], attr_names[attr], math.ceil(instance_sig_top*dataset.num_skin_tone_images[attr]), round(np.absolute(all_ratios_topn[index]), 4)))\n",
    "        \n",
    "p_values = np.zeros_like(counts_mat[0])\n",
    "attributes = np.array([[[-1,-1] for a in range(len(counts_mat[0][0]))] for b in range(len(counts_mat[0]))])\n",
    "mi = [np.zeros_like(counts_mat[0]) for a in range(num_attrs)]\n",
    "mi_wilson = [np.zeros_like(counts_mat[0]) for a in range(num_attrs)]\n",
    "\n",
    "for i in range(len(categories)):\n",
    "    for j in range(len(categories)):\n",
    "        if categories[i] in dataset.people_labels or categories[j] in dataset.people_labels:\n",
    "            p_values[i][j] = -1\n",
    "        else:\n",
    "            min_p = float('inf')\n",
    "            attr1 = -1\n",
    "            attr2 = -1\n",
    "            for a in range(num_attrs):\n",
    "                for b in range(a+1, num_attrs):\n",
    "                    len_a = instance_counts[a][j] + instance_counts[a][i] - counts_mat[a][i][j]\n",
    "                    an = np.zeros(int(len_a))\n",
    "                    an[:int(counts_mat[a][i][j])] = 1\n",
    "                    mi[a][i][j] = np.mean(an)\n",
    "                    mi_wilson[a][i][j] = wilson(np.mean(an), len_a)[0]\n",
    "                    \n",
    "                    len_b = instance_counts[b][j] + instance_counts[b][i] - counts_mat[b][i][j]\n",
    "                    bn = np.zeros(int(len_b))\n",
    "                    bn[:int(counts_mat[b][i][j])] = 1\n",
    "                    mi[b][i][j] = np.mean(bn)\n",
    "                    mi_wilson[b][i][j] = wilson(np.mean(bn), len_b)[0]\n",
    "                    p = stats.ttest_ind(an, bn)[1]\n",
    "                    if p < min_p:\n",
    "                        min_p = p\n",
    "                        attr1 = a\n",
    "                        attr2 = b\n",
    "            p_values[i][j] = p\n",
    "            attributes[i][j][0] = attr1\n",
    "            attributes[i][j][1] = attr2\n",
    "flat_p = p_values.flatten()\n",
    "flat_p[flat_p!=flat_p] = float(\"inf\")\n",
    "flat_p[flat_p == -1] = float(\"inf\")\n",
    "\n",
    "flat_attributes = attributes.flatten()\n",
    "attributes_dict = {}\n",
    "for i in range(len(flat_p)):\n",
    "    #Per 2 attributes in a ttest\n",
    "    attributes_dict[flat_p[i]] = [flat_attributes[2*i], flat_attributes[2*i+1]]\n",
    "    \n",
    "normalized_indices = np.argsort(flat_p)\n",
    "\n",
    "def cooccurrence_counts_mi(topn):\n",
    "    print(\"Statistically significant mutual information:\\n\")\n",
    "    i, j = 0, 0\n",
    "    while j < topn:\n",
    "        index = normalized_indices[i]\n",
    "        a, b = index % len(categories), index // len(categories)\n",
    "        if a < b:\n",
    "            attr1 = attributes_dict[flat_p[index]][0]\n",
    "            attr2 = attributes_dict[flat_p[index]][1]\n",
    "            print(\"{0} - {1}: {2}\".format(names[categories[a]], names[categories[b]], '{:0.3e}'.format(flat_p[index])))\n",
    "            print(\"{0}: {1}, {2}: {3}\".format(attr_names[attr1], round(mi[attr1].flatten()[index], 4), attr_names[attr2], round(mi[attr2].flatten()[index], 4)))\n",
    "            print()\n",
    "            j += 1\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "<a id=\"att_cnt_analyses\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of object categories by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset.group_mapping is not None:\n",
    "    supercategory_by_attribute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio between how often an object is represented with each gender (normalized), sorted by p-value or ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instanceratio_slider = widgets.IntSlider(min=5, max=50, step=1, value=10)\n",
    "instanceratio_sortby = widgets.Dropdown(options=['pvalue', 'ratio'], value='pvalue')\n",
    "\n",
    "if first_pass:\n",
    "    show_instance_ratios('pvalue', None)\n",
    "\n",
    "all_things = [instanceratio_sortby, instanceratio_slider]\n",
    "ui = HBox(all_things)\n",
    "out = widgets.interactive_output(show_instance_ratios, {'sort_by': instanceratio_sortby, 'topn': instanceratio_slider})\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most statistically significant object cooccurrences, measured by mutual information, between the attributes. The p-value is shown for the difference of the distributions, and the numbers for each specific attribute value indicate the mutual information for each attribute on the object pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(cooccurrence_counts_mi, topn=widgets.IntSlider(min=1, max=30, step=1, value=10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# att_clu Metric: Linearly separable objects by attribute\n",
    "<a id=\"att_clu\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "<a id=\"att_clu_setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_toggle(for_next=True, toggle_text='Show/hide att_clu code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "if not os.path.exists(\"results/{0}/att_clu/\".format(folder_name)):\n",
    "    os.mkdir(\"results/{0}/att_clu/\".format(folder_name))\n",
    "categories = dataset.categories\n",
    "names = dataset.labels_to_names\n",
    "stats_dict = pickle.load(open(\"results/{0}/att_clu.pkl\".format(folder_name), \"rb\"))\n",
    "instances = stats_dict['instance']\n",
    "scenes = stats_dict['scene']\n",
    "scene_filepaths = stats_dict['scene_filepaths']\n",
    "\n",
    "file_name = 'categories_places365.txt'\n",
    "if not os.access(file_name, os.W_OK):\n",
    "    synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "    os.system('wget ' + synset_url)\n",
    "classes = list()\n",
    "with open(file_name) as class_file:\n",
    "    for line in class_file:\n",
    "        classes.append(line.strip().split(' ')[0][3:])\n",
    "scene_classes = tuple(classes)\n",
    "\n",
    "topn = 15\n",
    "\n",
    "plot_kwds = {'alpha' : .8, 's' : 30, 'linewidths':0}\n",
    "\n",
    "instance_p_values = []\n",
    "scene_p_values = []\n",
    "\n",
    "file.write(\"SVM accuracies\\n\")\n",
    "\n",
    "if not os.path.exists(\"checkpoints/{}/att_clu.pkl\".format(folder_name)):\n",
    "    value_to_phrase = {}\n",
    "    value_to_scenephrase = {}\n",
    "    for i in range(len(categories)):\n",
    "        # SVM's to classify between an object's features for each attribute\n",
    "        clf = svm.SVC(kernel='linear', probability=False, max_iter=5000)\n",
    "        clf_prob = svm.SVC(kernel='linear', probability=True)\n",
    "        cont = False\n",
    "        for j in range(num_attrs):\n",
    "            if len(instances[i][j]) <= 1:\n",
    "                scene_p_values.append(float('inf'))\n",
    "                instance_p_values.append(float('inf'))\n",
    "                cont = True\n",
    "        if cont:\n",
    "            continue\n",
    "        \n",
    "        features_instances = np.concatenate([instances[i][j] for j in range(num_attrs) if len(instances[i][j]) != 0], axis=0)\n",
    "        boundary_instances = [len(instances[i][j]) for j in range(num_attrs)]\n",
    "        features_scenes = np.concatenate([scenes[i][j] for j in range(num_attrs) if len(scenes[i][j]) != 0], axis=0)\n",
    "        boundary_scenes = [len(scenes[i][j]) for j in range(num_attrs)]\n",
    "\n",
    "        # Uncomment to visualize features of cropped object, saved as a png\n",
    "        # projection_instances = TSNE().fit_transform(features_instances)\n",
    "        # plt.scatter(*projection_instances.T, **plot_kwds, c=[COLORS[k] for k in range(num_attrs) for j in range(boundary_instances[k])])\n",
    "        # plt.savefig(\"results/{0}/{1}/instances_{2}.png\".format(folder_name, 4, i))\n",
    "        # plt.close()\n",
    "\n",
    "        current_p_values = []\n",
    "        for j in range(num_attrs):\n",
    "            for k in range(j + 1, num_attrs):\n",
    "                t, p = stats.ttest_ind(instances[i][j], instances[i][k])\n",
    "                current_p_values.append(np.nanmean(p))\n",
    "        instance_p_values.append(current_p_values)\n",
    "\n",
    "        # Uncomment to visualize features of entire scene, saved as a png\n",
    "        # projection_scenes = TSNE().fit_transform(features_scenes)\n",
    "        # plt.scatter(*projection_scenes.T, **plot_kwds, c=[COLORS[k] for k in range(num_attrs) for j in range(boundary_scenes[k])])\n",
    "        # plt.savefig(\"results/{0}/{1}/scenes_{2}.png\".format(folder_name, 4, i))\n",
    "        # plt.close()\n",
    "\n",
    "        current_p_values = []\n",
    "        for j in range(num_attrs):\n",
    "            for k in range(j + 1, num_attrs):\n",
    "                t, p = stats.ttest_ind(scenes[i][j], scenes[i][k])\n",
    "                current_p_values.append(np.nanmean(p))\n",
    "        scene_p_values.append(current_p_values)\n",
    "\n",
    "        num_features = int(np.sqrt(len(features_scenes)))\n",
    "\n",
    "        labels = np.zeros(len(features_scenes))\n",
    "        idx = 0\n",
    "        for j in range(num_attrs):\n",
    "            labels[idx:] = j\n",
    "            idx += len(scenes[i][j])\n",
    "        \n",
    "        projected_features_scenes = StandardScaler().fit_transform(project(features_scenes, num_features))\n",
    "\n",
    "        clf.fit(projected_features_scenes, labels)\n",
    "        clf_prob.fit(projected_features_scenes, labels)\n",
    "        acc = clf.score(projected_features_scenes, labels)\n",
    "        preds = clf.predict(projected_features_scenes)\n",
    "        probs = clf.decision_function(projected_features_scenes)\n",
    "        scaled_probs = clf_prob.predict_proba(projected_features_scenes)\n",
    "        \n",
    "        if (num_attrs == 2):\n",
    "            probs = np.stack([probs, -probs], axis=1)\n",
    "        \n",
    "        probs_copy = probs.copy()\n",
    "        probs_copy[probs_copy > 0] = 1\n",
    "        probs_copy[probs_copy < 0] = 0\n",
    "        target = np.zeros(probs_copy.shape)\n",
    "        target[np.arange(target.shape[0]), labels.astype(int)] = 1\n",
    "        accs = []\n",
    "        for j in range(num_attrs):\n",
    "            accs.append(np.sum(target[:, j] == probs_copy[:, j]))\n",
    "        most_acc_attr = np.argmax(accs)\n",
    "\n",
    "        a_probs = []\n",
    "        b_probs = []\n",
    "        split_filepaths = [[], []]\n",
    "        total_offset, curr_idx = 0, 0\n",
    "        for j in range(len(features_scenes)):\n",
    "            if j - total_offset >= boundary_scenes[curr_idx]:\n",
    "                total_offset += boundary_scenes[curr_idx]\n",
    "                curr_idx += 1\n",
    "            if labels[j] == most_acc_attr:\n",
    "                a_probs.append(probs[j][most_acc_attr])\n",
    "                split_filepaths[0].append(scene_filepaths[i][int(labels[j])][j - total_offset])\n",
    "            else:\n",
    "                b_probs.append(-probs[j][most_acc_attr])\n",
    "                split_filepaths[1].append(scene_filepaths[i][int(labels[j])][j - total_offset])\n",
    "                \n",
    "        a_indices = np.argsort(np.array(a_probs))\n",
    "        b_indices = np.argsort(np.array(b_probs))\n",
    "\n",
    "        pickle.dump([a_indices, b_indices, split_filepaths, a_probs, b_probs, most_acc_attr], open(\"results/{0}/att_clu/{1}_info.pkl\".format(folder_name, names[categories[i]]), \"wb\"))\n",
    "        \n",
    "        base_acc, rand_acc, p_value = permutation_test_score(clf, projected_features_scenes, labels, scoring=\"accuracy\", n_permutations=100)\n",
    "        ratio = base_acc/np.mean(rand_acc)\n",
    "\n",
    "        if p_value > 0.05 and ratio <= 1.2: # can tune as desired\n",
    "            continue\n",
    "\n",
    "        amount = len(features_instances)\n",
    "        phrase = [ratio, names[categories[i]], acc, p_value, len(features_instances), num_features]\n",
    "        value_to_phrase[i] = phrase\n",
    "        \n",
    "        total_offset = 0\n",
    "        scenes_per_attr = [[[] for j in range(num_attrs)] for i in range(len(scene_classes))]\n",
    "        for c in range(num_attrs):\n",
    "            for j in range(boundary_scenes[c]):\n",
    "                this_scene = scene_filepaths[i][c][j][1]\n",
    "                scenes_per_attr[this_scene][c].append(np.absolute(scaled_probs[j + total_offset][c]))\n",
    "            total_offset += boundary_scenes[c]\n",
    "            \n",
    "        for j in range(len(scene_classes)):\n",
    "            dists = [scenes_per_attr[j][k] for k in range(num_attrs)]\n",
    "            all_a = [np.zeros(len(scenes[i][k])) for k in range(num_attrs)]\n",
    "            for d, a in zip(dists, all_a):\n",
    "                a[:len(d)] = 1\n",
    "            for k in range(num_attrs):\n",
    "                for l in range(k + 1, num_attrs):\n",
    "                    _, p = stats.ttest_ind(all_a[k], all_a[l])\n",
    "                    if not np.isnan(p):\n",
    "                        value_to_scenephrase[p] = [names[categories[i]], scene_classes[j], len(dists[k]), len(all_a[k]), len(dists[l]), len(all_a[l]), attr_names[k], attr_names[l]]\n",
    "                        \n",
    "    pickle.dump([value_to_phrase, value_to_scenephrase], open(\"checkpoints/{}/att_clu.pkl\".format(folder_name), 'wb'))\n",
    "else:\n",
    "    value_to_phrase, value_to_scenephrase = pickle.load(open(\"checkpoints/{}/att_clu.pkl\".format(folder_name), 'rb'))\n",
    "\n",
    "def label_svm_qual(category, num):\n",
    "    to_save = False\n",
    "    ratio, name, acc, p_value, num_examples, num_features = value_to_phrase[category]\n",
    "    a_indices, b_indices, split_filepaths, a_probs, b_probs, most_acc_attr = pickle.load(open(\"results/{0}/att_clu/{1}_info.pkl\".format(folder_name, name), \"rb\"))\n",
    "    print_statement = \"{3}: Accuracy: {0}%, with p={1}, {2}x and {3} features\".format(round(acc*100., 3), round(p_value, 3), round(ratio, 3), num_features, name)\n",
    "    attr_statement = \"\\\"{0}\\\" had the highest classification accuracy\\n\".format(attr_names[most_acc_attr])\n",
    "    if num is None and first_pass:\n",
    "        to_save = True\n",
    "        num = 5\n",
    "        to_write[6] = [\"(att_clu) To discern if there is an appearance difference in how attributes are imaged with an object, we extract scene-level features from each image, and fit a linear SVM to distinguish between the them.\\nAn example of the most linearly separable object between attributes: {}\".format(name), print_statement]\n",
    "    else:\n",
    "        print(print_statement)\n",
    "        print(attr_statement)\n",
    "        \n",
    "    the_indices = [a_indices, b_indices]\n",
    "    the_probs = [a_probs, b_probs]\n",
    "    \n",
    "    def display_chunk(b=0, correct=True, to_save=False, name=None):\n",
    "        this_filepaths = split_filepaths[b]\n",
    "        this_indices = the_indices[b]\n",
    "        this_probs = the_probs[b]\n",
    "        collected_filepaths = []\n",
    "        \n",
    "        if correct:\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter = -1\n",
    "        while len(collected_filepaths) < num:\n",
    "            try:\n",
    "                index = this_indices[counter]\n",
    "            except:\n",
    "                break\n",
    "            file_path = this_filepaths[index][0]\n",
    "            if (this_probs[index] > 0 and correct) or (this_probs[index] < 0 and not correct):\n",
    "                collected_filepaths.append(file_path)\n",
    "            if correct:\n",
    "                counter += 1\n",
    "            else:\n",
    "                counter += -1\n",
    "        if to_save and first_pass:\n",
    "            this_loc = \"results/{0}/{1}/att_clu_{2}.png\".format(folder_name, save_loc, name)\n",
    "            if len(collected_filepaths) > 0:\n",
    "                fig = plt.figure(figsize=(16, 8))\n",
    "                for i in range(num):\n",
    "                    ax = fig.add_subplot(1, num, i+1)\n",
    "                    ax.axis(\"off\")\n",
    "                    if i >= len(collected_filepaths):\n",
    "                        image = np.ones((3, 3, 3))\n",
    "                    else:\n",
    "                        image, _ = dataset.from_path(collected_filepaths[i])\n",
    "                        image = image.data.cpu().numpy().transpose(1, 2, 0)\n",
    "                    im = ax.imshow(image, extent=SAME_EXTENT)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(this_loc, bbox_inches = 'tight')\n",
    "                plt.close()\n",
    "            else:\n",
    "                os.system(\"cp util_files/no_images.png {}\".format(this_loc))\n",
    "        elif len(collected_filepaths) > 0:\n",
    "            display_filepaths(collected_filepaths, width = 800//len(collected_filepaths), height=800//len(collected_filepaths))\n",
    "        else:\n",
    "            print(\"No images in this category\")\n",
    "            \n",
    "    \n",
    "    if not to_save:\n",
    "        print(\"{}: Correct\".format(attr_names[most_acc_attr]))\n",
    "    else:\n",
    "        to_write[6].append(\"{}: Correct\".format(attr_names[most_acc_attr]))\n",
    "    display_chunk(0, True, to_save, 'a')\n",
    "    if not to_save:\n",
    "        print(\"{}: Incorrect\".format(attr_names[most_acc_attr]))\n",
    "    else:\n",
    "        to_write[6].append(\"{}: Incorrect\".format(attr_names[most_acc_attr]))\n",
    "    display_chunk(0, False, to_save, 'b')\n",
    "    if not to_save:\n",
    "        print(\"Not {}: Correct\".format(attr_names[most_acc_attr]))\n",
    "    else:\n",
    "        to_write[6].append(\"Not-{}: Correct\".format(attr_names[most_acc_attr]))\n",
    "    display_chunk(1, True, to_save, 'c')\n",
    "    if not to_save:\n",
    "        print(\"Not {}: Incorrect\".format(attr_names[most_acc_attr]))\n",
    "    else:\n",
    "        to_write[6].append(\"Not-{}: Incorrect\".format(attr_names[most_acc_attr]))\n",
    "    display_chunk(1, False, to_save, 'd')\n",
    "    \n",
    "cat_svm_options = []\n",
    "most_different_cat_value = 1.2\n",
    "most_different_cat = None\n",
    "\n",
    "for index, phrase in sorted(value_to_phrase.items(), key=lambda kv: kv[1][0], reverse=True):\n",
    "    ratio, name, acc, p_value, num_examples, num_features = value_to_phrase[index]\n",
    "    if acc > .75 and ratio > most_different_cat_value and num_features > 5:\n",
    "        most_different_cat_value = ratio\n",
    "        most_different_cat = index\n",
    "    if num_features > 4:\n",
    "        cat_svm_options.append(('{0}: {1}% and {2}x'.format(name, round(100.*acc, 2), round(ratio, 3)), index))\n",
    "\n",
    "def instance_diff_by_scene(topn):\n",
    "    print(\"\\nInstance differences by scene between attributes\\n\")\n",
    "    i = 0\n",
    "    for value, phr in sorted(value_to_scenephrase.items(), key=lambda kv: kv[0], reverse=False):\n",
    "        pair = \"({0}, {1})\".format(phr[6], phr[7])\n",
    "        print(\"{9:15} {0} p-value, {1}: in {2} for {3} of {4} {7}, and {5} of {6} {8}\".format(dec_to_show(value), phr[0], phr[1], phr[2], phr[3], phr[4], phr[5], phr[6], phr[7], pair[0:15]))\n",
    "        if i == topn:\n",
    "            break\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyses\n",
    "<a id=\"att_clu_analyses\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitative examples of the most linearly separable objects once featurized, by attribute. Attributes are predicted using a one-vs-rest scheme, where a model is fit for each attribute (against the other attributes) and the model with the highest score is taken as the predicted label. Permutation test p-values are given to check for random overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_qual_widget = widgets.IntSlider(min=1, max=20, step=1, value=5)\n",
    "cat_choice_widget = widgets.Dropdown(options=cat_svm_options, layout=Layout(width='400px'))\n",
    "all_things = [widgets.Label('Category, p_value, acc',layout=Layout(padding='0px 0px 0px 5px', width='200px')), cat_choice_widget, widgets.Label('Num',layout=Layout(padding='0px 5px 0px 40px', width='80px')), num_qual_widget]\n",
    "\n",
    "if first_pass and most_different_cat is not None:\n",
    "    label_svm_qual(most_different_cat, None)\n",
    "ui = HBox(all_things)\n",
    "out = widgets.interactive_output(label_svm_qual, {'category': cat_choice_widget, 'num': num_qual_widget})\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences in scene between attribute for an object. Analyses on random sample of up to 500 for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(instance_diff_by_scene, topn=widgets.IntSlider(min=1, max=30, step=1, value=10));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}